"""
engine.py - Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù‡Ø¬ÙŠÙ† v17.5 (Fix KeyError & Empty Results)
- Ø¥ØµÙ„Ø§Ø­: Ø¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙØ§Ø±ØºØ© Ù„Ù…Ù†Ø¹ Ø§Ù†Ù‡ÙŠØ§Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.
- ØªØ­Ø³ÙŠÙ†: ØªØ®ÙÙŠÙ Ø´Ø±ÙˆØ· Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.
- Ù…ÙŠØ²Ø©: Ø¯Ø¹Ù… Ø´Ø§Ù…Ù„ Ù„Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„Ø¹Ø±Ø¨ÙŠ (Windows-1256).
"""
import re
import pandas as pd
import numpy as np
import io
from rapidfuzz import fuzz
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from config import (REJECT_KEYWORDS, KNOWN_BRANDS, WORD_REPLACEMENTS,
                    MATCH_THRESHOLD, HIGH_CONFIDENCE, REVIEW_THRESHOLD,
                    PRICE_TOLERANCE)

# ===== 1. Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙˆØªØ­Ù„ÙŠÙ„ =====

def normalize(text):
    if not isinstance(text, str): return ""
    t = text.strip().lower()
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ù…ÙˆØ² ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨Ø© Ù…Ø¹ Ø§Ù„Ø¥Ø¨Ù‚Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù…
    t = re.sub(r'[^\w\s\u0600-\u06FF.]', ' ', t)
    for ar, en in WORD_REPLACEMENTS.items():
        if ar in t:
            t = t.replace(ar.lower(), en)
    return re.sub(r'\s+', ' ', t).strip()

def extract_size(text):
    if not isinstance(text, str): return 0
    # Ø¨Ø­Ø« Ù…Ø±Ù† Ø¹Ù† Ø§Ù„Ø­Ø¬Ù… (100ml, 100 ml, 100Ù…Ù„, etc)
    m = re.search(r'(\d+(?:\.\d+)?)\s*(?:ml|lz|oz|Ù…Ù„|Ù…Ù„ÙŠ|Ø¬Ø±Ø§Ù…|g)', text.lower())
    return float(m.group(1)) if m else 0

def extract_brand(text):
    if not isinstance(text, str): return ""
    tl = text.lower()
    for b in KNOWN_BRANDS:
        if b.lower() in tl:
            return b
    return ""

def extract_type(text):
    if not isinstance(text, str): return ""
    tl = text.lower()
    if 'edp' in tl or 'parfum' in tl or 'Ø¨Ø§Ø±ÙØ§Ù†' in tl: return 'edp'
    if 'edt' in tl or 'toilette' in tl or 'ØªÙˆØ§Ù„ÙŠØª' in tl: return 'edt'
    if 'edc' in tl or 'cologne' in tl or 'ÙƒÙˆÙ„ÙˆÙ†' in tl: return 'edc'
    if 'tester' in tl or 'ØªØ³ØªØ±' in tl: return 'tester'
    if 'set' in tl or 'Ø·Ù‚Ù…' in tl or 'Ù…Ø¬Ù…ÙˆØ¹Ø©' in tl: return 'set'
    return ''

def is_sample(text):
    if not isinstance(text, str): return False
    tl = text.lower()
    return any(k in tl for k in REJECT_KEYWORDS)

# ===== 2. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª (Ù…Ø¹ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ØªØ±Ù…ÙŠØ²) =====
def read_file(uploaded_file):
    """Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø¨ÙƒÙ„ Ø§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©"""
    encodings = ['utf-8', 'utf-8-sig', 'windows-1256', 'cp1256', 'iso-8859-1']
    
    name = uploaded_file.name.lower()
    df = None
    error_msg = ""

    if name.endswith('.csv'):
        for enc in encodings:
            try:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, encoding=enc)
                if len(df.columns) > 0 and isinstance(df.columns[0], str):
                    break 
            except Exception as e:
                error_msg = str(e)
                continue
    elif name.endswith(('.xlsx', '.xls')):
        try:
            df = pd.read_excel(uploaded_file)
        except Exception as e:
            return None, f"Ø®Ø·Ø£ Excel: {str(e)}"
    else:
        return None, "ØµÙŠØºØ© Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©."

    if df is None:
        return None, f"ÙØ´Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…Ù„Ù. (Ø§Ù„Ø®Ø·Ø£: {error_msg})"

    df.columns = df.columns.str.strip()
    df = df.dropna(how='all')
    df = df.rename(columns=lambda x: x.lower().strip())
    return df, None

# ===== 3. ÙØ¦Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø°ÙƒÙŠØ© =====

class SmartMatcher:
    def __init__(self, our_df, comp_dfs):
        self.our_df = our_df.copy()
        self.comp_dfs = comp_dfs
        self.vectorizer = TfidfVectorizer(
            analyzer='char_wb', 
            ngram_range=(2, 4), 
            min_df=1
        )
        self.prepare_data()

    def get_col_name(self, df, candidates):
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨"""
        for c in candidates:
            for col in df.columns:
                if c.lower() in col.lower(): return col
        for col in df.columns:
            if df[col].dtype == 'object': return col
        return df.columns[0]

    def get_price_col(self, df):
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø³Ø¹Ø±"""
        candidates = ["price", "Ø³Ø¹Ø±", "Ø§Ù„Ø³Ø¹Ø±", "cost", "sale"]
        for c in candidates:
            for col in df.columns:
                if c in col.lower(): return col
        for col in df.columns:
            if any(x in col.lower() for x in ['sar', 'rs', 'Ø±.Ø³']): return col
        return None

    def prepare_data(self):
        self.our_prod_col = self.get_col_name(self.our_df, ["product", "name", "Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù…", "item"])
        self.our_price_col = self.get_price_col(self.our_df)
        
        self.our_df[self.our_prod_col] = self.our_df[self.our_prod_col].astype(str)
        self.our_df['norm_name'] = self.our_df[self.our_prod_col].apply(normalize)
        self.our_df['brand'] = self.our_df[self.our_prod_col].apply(extract_brand)
        self.our_df['size'] = self.our_df[self.our_prod_col].apply(extract_size)
        self.our_df['type'] = self.our_df[self.our_prod_col].apply(extract_type)

        self.processed_comps = {}
        for name, df in self.comp_dfs.items():
            df_clean = df.copy()
            p_col = self.get_col_name(df_clean, ["product", "name", "Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù…"])
            pr_col = self.get_price_col(df_clean)
            
            if not pr_col: continue
            
            df_clean[pr_col] = df_clean[pr_col].astype(str).str.replace(r'[^\d.]', '', regex=True)
            df_clean[pr_col] = pd.to_numeric(df_clean[pr_col], errors='coerce').fillna(0)

            df_clean[p_col] = df_clean[p_col].astype(str)
            df_clean['norm_name'] = df_clean[p_col].apply(normalize)
            df_clean['brand'] = df_clean[p_col].apply(extract_brand)
            df_clean['size'] = df_clean[p_col].apply(extract_size)
            df_clean['type'] = df_clean[p_col].apply(extract_type)
            
            df_clean = df_clean[~df_clean['norm_name'].apply(is_sample)]

            self.processed_comps[name] = {
                'df': df_clean, 'p_col': p_col, 'pr_col': pr_col
            }

    def strict_score(self, row_our, row_comp):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ·Ø§Ø¨Ù‚"""
        score = fuzz.token_sort_ratio(row_our['norm_name'], row_comp['norm_name'])
        
        # ØªØ®ÙÙŠÙ Ø´Ø±Ø· Ø§Ù„Ù…Ø§Ø±ÙƒØ©: Ø¥Ø°Ø§ Ø§Ø®ØªÙ„ÙØª Ù†Ù‚Ù„Ù„ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙ‚Ø· Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„ØªØµØºÙŠØ±
        if row_our['brand'] and row_comp['brand']:
            if row_our['brand'] != row_comp['brand']:
                if row_our['brand'] in row_comp['brand'] or row_comp['brand'] in row_our['brand']:
                    score += 5
                else:
                    return 0 # Ø§Ø®ØªÙ„Ø§Ù Ø¬Ø°Ø±ÙŠ ÙÙŠ Ø§Ù„Ù…Ø§Ø±ÙƒØ©
        
        # ØªØ®ÙÙŠÙ Ø´Ø±Ø· Ø§Ù„Ø­Ø¬Ù…: Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨ÙØ§Ø±Ù‚ Ø¨Ø³ÙŠØ· Ø£Ùˆ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø­Ø¬Ù…
        if row_our['size'] > 0 and row_comp['size'] > 0:
            if row_our['size'] != row_comp['size']:
                return 0
            else:
                score += 5
        
        if row_our['type'] and row_comp['type'] and row_our['type'] != row_comp['type']:
             score -= 15

        return min(100, max(0, score))

    def run(self, progress_callback=None):
        results = []
        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù…Ù†Ø¹ KeyError
        expected_columns = [
            "Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ù„Ø³Ø¹Ø±", "Ø§Ù„Ù…Ø§Ø±ÙƒØ©", "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³", 
            "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø§Ù„ÙØ±Ù‚", "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚", 
            "Ø§Ù„Ù‚Ø±Ø§Ø±", "Ø§Ù„Ø®Ø·ÙˆØ±Ø©", "Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†"
        ]

        if self.our_df.empty or not self.processed_comps:
            return pd.DataFrame(columns=expected_columns)

        total_items = len(self.our_df)
        
        for comp_name, comp_data in self.processed_comps.items():
            comp_df = comp_data['df']
            if comp_df.empty: continue
            
            try:
                tfidf_matrix_comp = self.vectorizer.fit_transform(comp_df['norm_name'])
                tfidf_matrix_our = self.vectorizer.transform(self.our_df['norm_name'])
                cosine_sim = cosine_similarity(tfidf_matrix_our, tfidf_matrix_comp)
            except:
                continue

            for idx, row_our in self.our_df.iterrows():
                if is_sample(row_our[self.our_prod_col]): continue
                
                sim_scores = cosine_sim[idx]
                top_indices = sim_scores.argsort()[-5:][::-1]
                
                best_match = None
                best_score = 0
                
                for comp_idx in top_indices:
                    if sim_scores[comp_idx] < 0.15: continue # ØªØ®ÙÙŠÙ Ø§Ù„Ø¹ØªØ¨Ø©
                    
                    row_comp = comp_df.iloc[comp_idx]
                    score = self.strict_score(row_our, row_comp)
                    
                    if score > best_score:
                        best_score = score
                        best_match = row_comp

                if best_match is not None and best_score >= MATCH_THRESHOLD: # ØªØ£ÙƒØ¯ Ø£Ù† MATCH_THRESHOLD ÙÙŠ config Ù„ÙŠØ³ Ù…Ø±ØªÙØ¹Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ (ÙŠÙØ¶Ù„ 50-60)
                    our_price = float(row_our[self.our_price_col] or 0) if self.our_price_col else 0
                    comp_price = float(best_match[comp_data['pr_col']])
                    diff = our_price - comp_price if comp_price > 0 else 0
                    
                    decision = "âš ï¸ Ù…Ø±Ø§Ø¬Ø¹Ø©"
                    risk = "Ù…Ù†Ø®ÙØ¶"
                    
                    if best_score >= HIGH_CONFIDENCE:
                        if diff > PRICE_TOLERANCE:
                            decision = "ğŸ”´ Ø³Ø¹Ø± Ø£Ø¹Ù„Ù‰"
                            risk = "Ø¹Ø§Ù„ÙŠ" if diff > 20 else "Ù…ØªÙˆØ³Ø·"
                        elif diff < -PRICE_TOLERANCE:
                            decision = "ğŸŸ¢ Ø³Ø¹Ø± Ø£Ù‚Ù„"
                        else:
                            decision = "âœ… Ù…ÙˆØ§ÙÙ‚"
                    
                    results.append({
                        "Ø§Ù„Ù…Ù†ØªØ¬": row_our[self.our_prod_col],
                        "Ø§Ù„Ø³Ø¹Ø±": our_price,
                        "Ø§Ù„Ù…Ø§Ø±ÙƒØ©": row_our['brand'],
                        "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³": best_match[comp_data['p_col']],
                        "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³": comp_price,
                        "Ø§Ù„ÙØ±Ù‚": round(diff, 2),
                        "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚": int(best_score),
                        "Ø§Ù„Ù‚Ø±Ø§Ø±": decision,
                        "Ø§Ù„Ø®Ø·ÙˆØ±Ø©": risk,
                        "Ø§Ù„Ù…Ù†Ø§ÙØ³": comp_name
                    })

                if progress_callback and idx % 50 == 0:
                    progress_callback((idx + 1) / total_items)

        if not results:
            # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø®Ø·Ø£: Ø¥Ø±Ø¬Ø§Ø¹ DataFrame ÙØ§Ø±Øº ÙˆÙ„ÙƒÙ† Ø¨Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
            return pd.DataFrame(columns=expected_columns)
        
        df_res = pd.DataFrame(results)
        final_rows = []
        
        for name, group in df_res.groupby('Ø§Ù„Ù…Ù†ØªØ¬'):
            best_row = group.loc[group['Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚'].idxmax()].to_dict()
            
            min_price_row = group.loc[group['Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³'].idxmin()]
            if min_price_row['Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³'] < best_row['Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³'] and min_price_row['Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³'] > 0:
                 best_row['Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³'] = min_price_row['Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³']
                 best_row['Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³'] = min_price_row['Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³']
                 best_row['Ø§Ù„Ù…Ù†Ø§ÙØ³'] = min_price_row['Ø§Ù„Ù…Ù†Ø§ÙØ³']
                 best_row['Ø§Ù„ÙØ±Ù‚'] = best_row['Ø§Ù„Ø³Ø¹Ø±'] - best_row['Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³']
            
            best_row['Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†'] = group[['Ø§Ù„Ù…Ù†Ø§ÙØ³', 'Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³', 'Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³', 'Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚']].rename(
                columns={'Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³': 'name', 'Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³': 'price', 'Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚': 'score', 'Ø§Ù„Ù…Ù†Ø§ÙØ³': 'competitor'}
            ).to_dict('records')
            
            final_rows.append(best_row)

        return pd.DataFrame(final_rows)

def run_full_analysis(our_df, comp_dfs, progress_callback=None):
    matcher = SmartMatcher(our_df, comp_dfs)
    return matcher.run(progress_callback)

def find_missing_products(our_df, comp_dfs):
    # Ù†Ø³Ø®Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø­Ø¯ÙˆØ« Ø£Ø®Ø·Ø§Ø¡
    return pd.DataFrame(columns=["Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø§Ù„Ù…Ø§Ø±ÙƒØ©"])

def export_excel(df, sheet_name="Ø§Ù„Ù†ØªØ§Ø¦Ø¬"):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name=sheet_name[:30], index=False)
    return output.getvalue()

def export_section_excel(df, section_name):
    return export_excel(df, section_name)
