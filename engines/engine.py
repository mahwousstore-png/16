"""
engine.py - Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ Ø§Ù„ØµØ§Ø±Ù… v18.0
- Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„ÙƒÙ„ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù†ØµÙŠ.
- ØªØ·Ø¨ÙŠÙ‚ ÙÙ„Ø§ØªØ±: Ø§Ù„Ù…Ø§Ø±ÙƒØ© (Ø¥Ø¬Ø¨Ø§Ø±ÙŠ)ØŒ Ø§Ù„Ù†ÙˆØ¹ (Ø¥Ø¬Ø¨Ø§Ø±ÙŠ)ØŒ Ø§Ù„Ø­Ø¬Ù… (Ø¥Ø¬Ø¨Ø§Ø±ÙŠ).
"""
import re
import pandas as pd
from rapidfuzz import fuzz
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from config import KNOWN_BRANDS, WORD_REPLACEMENTS, REJECT_KEYWORDS

# ==========================================
# 1. Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØµÙ†ÙŠÙ ÙˆØ§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ (Ù‚Ù„Ø¨ Ø§Ù„Ù†Ø¸Ø§Ù…)
# ==========================================

def normalize(text):
    if not isinstance(text, str): return ""
    t = text.strip().lower()
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ù…ÙˆØ²
    t = re.sub(r'[^\w\s\u0600-\u06FF.]', ' ', t)
    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª (Ù…Ø«Ù„ Ø§Ùˆ Ø¯Ùˆ Ø¨Ø§Ø±ÙÙŠÙˆÙ… -> edp)
    for ar, en in WORD_REPLACEMENTS.items():
        if ar in t: t = t.replace(ar, en)
    return re.sub(r'\s+', ' ', t).strip()

def extract_brand(text):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø§Ø±ÙƒØ© Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©"""
    if not isinstance(text, str): return "unknown"
    t = text.lower()
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø¨Ø§Ù„Ø£Ø·ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹ Ù„ØªÙØ§Ø¯ÙŠ Ø§Ù„Ø®Ø·Ø£ (Ù…Ø«Ù„ Tom Ford Ù‚Ø¨Ù„ Ford)
    brands = sorted(KNOWN_BRANDS, key=len, reverse=True)
    for b in brands:
        if b.lower() in t:
            return b.lower()
    return "unknown"

def extract_size(text):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø¬Ù… (Ù…Ù„/Ø¬Ø±Ø§Ù…)"""
    if not isinstance(text, str): return 0
    # 100ml, 100 ml, 100Ù…Ù„, 100 g
    m = re.search(r'(\d+)\s*(?:ml|lz|oz|Ù…Ù„|Ù…Ù„ÙŠ|g|gm|gram|Ø¬Ø±Ø§Ù…)', text.lower())
    return int(m.group(1)) if m else 0

def get_product_nature(text):
    """ØªØ­Ø¯ÙŠØ¯ Ù‡ÙˆÙŠØ© Ø§Ù„Ù…Ù†ØªØ¬ (Ø¹Ø·Ø±ØŒ Ø´Ø¹Ø±ØŒ Ø¬Ø³Ù…ØŒ Ø·Ù‚Ù…ØŒ Ø¹ÙŠÙ†Ø©)"""
    t = text.lower()
    
    if any(x in t for x in ['set', 'gift', 'Ø·Ù‚Ù…', 'Ù…Ø¬Ù…ÙˆØ¹Ø©', 'Ø¨ÙƒØ¬']): return 'set'
    if any(x in t for x in ['hair', 'mist', 'Ø´Ø¹Ø±', 'Ù…Ø¹Ø·Ø± Ø´Ø¹Ø±']): return 'hair'
    if any(x in t for x in ['body', 'lotion', 'cream', 'gel', 'Ø¬Ø³Ù…', 'Ù„ÙˆØ´Ù†', 'ÙƒØ±ÙŠÙ…', 'Ù…Ø¹Ø·Ø± Ø¬Ø³Ù…']): return 'body'
    if any(x in t for x in ['sample', 'vial', 'tester', 'test', 'Ø¹ÙŠÙ†Ø©', 'ØªØ³ØªØ±']): return 'sample'
    if any(x in t for x in ['powder', 'foundation', 'blush', 'Ø¨ÙˆØ¯Ø±Ø©', 'Ø£Ø­Ù…Ø± Ø®Ø¯ÙˆØ¯']): return 'makeup'
    if any(x in t for x in ['oil', 'Ø²ÙŠØª']): return 'oil'
    
    return 'perfume' # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ

# ==========================================
# 2. ÙƒÙ„Ø§Ø³ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©
# ==========================================

class StrictMatcher:
    def __init__(self, our_df, comp_dfs, mapping=None):
        self.our_df = our_df.copy()
        self.comp_dfs = comp_dfs
        self.mapping = mapping
        # Ù†Ø³ØªØ®Ø¯Ù… TF-IDF ÙÙ‚Ø· Ù„Ù„ÙÙ„ØªØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
        self.vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=1)
        self.prepare_data()

    def prepare_data(self):
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        if self.mapping:
            self.our_p = self.mapping.get('our_name')
            self.our_pr = self.mapping.get('our_price')
        else:
            self.our_p = self.our_df.columns[0]
            self.our_pr = self.our_df.columns[1]

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§ØªÙ†Ø§
        self.our_df['clean_name'] = self.our_df[self.our_p].astype(str).apply(normalize)
        self.our_df['brand'] = self.our_df[self.our_p].apply(extract_brand)
        self.our_df['size'] = self.our_df[self.our_p].apply(extract_size)
        self.our_df['nature'] = self.our_df[self.our_p].apply(get_product_nature)

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†
        self.processed_comps = {}
        for name, df in self.comp_dfs.items():
            cdf = df.copy()
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ± ÙÙŠ Ø§Ù„Ù…Ø§Ø¨ÙŠÙ†Ø¬
            if self.mapping:
                cp = self.mapping.get('comp_name', cdf.columns[0])
                cpr = self.mapping.get('comp_price', cdf.columns[1])
            else:
                cp = cdf.columns[0]
                cpr = cdf.columns[1]

            cdf['clean_name'] = cdf[cp].astype(str).apply(normalize)
            cdf['brand'] = cdf[cp].apply(extract_brand)
            cdf['size'] = cdf[cp].apply(extract_size)
            cdf['nature'] = cdf[cp].apply(get_product_nature)
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¹Ø±
            cdf[cpr] = pd.to_numeric(cdf[cpr].astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce').fillna(0)
            
            self.processed_comps[name] = {'df': cdf, 'p_col': cp, 'pr_col': cpr}

    def check_logic_match(self, row1, row2):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ Ø§Ù„ØµØ§Ø±Ù… (ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙ…Ø± Ù„ØªÙ‚Ø¨Ù„ Ø§Ù„Ù†ØªÙŠØ¬Ø©)"""
        
        # 1. Ø§Ø®ØªÙ„Ø§Ù Ø§Ù„Ù…Ø§Ø±ÙƒØ© = Ø±ÙØ¶ Ù‚Ø§Ø·Ø¹
        # (Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ© ÙÙŠ Ø£Ø­Ø¯Ù‡Ù…Ø§ØŒ Ù†ØªØ³Ø§Ù‡Ù„ Ù‚Ù„ÙŠÙ„Ø§Ù‹ ÙˆÙ†Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù…)
        if row1['brand'] != 'unknown' and row2['brand'] != 'unknown':
            if row1['brand'] != row2['brand']:
                return False, "Ù…Ø§Ø±ÙƒØ© Ù…Ø®ØªÙ„ÙØ©"

        # 2. Ø§Ø®ØªÙ„Ø§Ù Ø§Ù„Ø·Ø¨ÙŠØ¹Ø© = Ø±ÙØ¶ Ù‚Ø§Ø·Ø¹
        # Ù…Ø³ØªØ­ÙŠÙ„ Ù†Ø·Ø§Ø¨Ù‚ (Ø¹Ø·Ø± Ø´Ø¹Ø±) Ø¨Ù€ (Ø¹Ø·Ø±) Ø£Ùˆ (Ø·Ù‚Ù…) Ø¨Ù€ (Ø¹Ø·Ø±)
        if row1['nature'] != row2['nature']:
            # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø¨Ø³ÙŠØ·: Ø§Ù„ØªØ³ØªØ± ÙˆØ§Ù„Ø¹Ø·Ø± Ø§Ù„Ø¹Ø§Ø¯ÙŠ ÙŠÙ…ÙƒÙ† Ù…Ø·Ø§Ø¨Ù‚ØªÙ‡Ù…Ø§
            if {row1['nature'], row2['nature']} == {'perfume', 'sample'}: 
                pass # Ù…Ø³Ù…ÙˆØ­ (ØªØ³ØªØ± Ù…Ø¹ Ø¹Ø·Ø±)
            elif 'sample' in [row1['nature'], row2['nature']]:
                 # Ø¥Ø°Ø§ Ø£Ø­Ø¯Ù‡Ù…Ø§ Ø¹ÙŠÙ†Ø© ÙˆØ§Ù„Ø¢Ø®Ø± Ù„Ø§ØŒ ÙˆØ§Ù„Ø£Ø³Ù…Ø§Ø¡ Ù…ØªØ´Ø§Ø¨Ù‡Ø©ØŒ Ù†Ù‚Ø¨Ù„Ù‡Ø§ ÙˆÙ„ÙƒÙ† Ù†Ø¶Ø¹ Ø¹Ù„Ø§Ù…Ø©
                 pass 
            else:
                return False, f"Ù†ÙˆØ¹ Ù…Ø®ØªÙ„Ù ({row1['nature']} vs {row2['nature']})"

        # 3. Ø§Ø®ØªÙ„Ø§Ù Ø§Ù„Ø­Ø¬Ù… (Ø¥Ø°Ø§ ÙˆØ¬Ø¯ ÙÙŠ Ø§Ù„Ø§Ø«Ù†ÙŠÙ†)
        if row1['size'] > 0 and row2['size'] > 0:
            if row1['size'] != row2['size']:
                return False, f"Ø­Ø¬Ù… Ù…Ø®ØªÙ„Ù ({row1['size']} vs {row2['size']})"

        return True, "ok"

    def run(self, progress_callback=None):
        results = []
        total = len(self.our_df)
        
        for comp_name, comp_data in self.processed_comps.items():
            comp_df = comp_data['df']
            if comp_df.empty: continue

            # Vectorization Ù„Ù„ØªØ³Ø±ÙŠØ¹ ÙÙ‚Ø· (ÙˆÙ„ÙŠØ³ Ù„Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ)
            try:
                tfidf_c = self.vectorizer.fit_transform(comp_df['clean_name'])
                tfidf_o = self.vectorizer.transform(self.our_df['clean_name'])
                cosine_sim = cosine_similarity(tfidf_o, tfidf_c)
            except: continue

            for i, row_our in self.our_df.iterrows():
                # Ø£ÙØ¶Ù„ 5 Ù…Ø±Ø´Ø­ÙŠÙ† Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ
                top_indices = cosine_sim[i].argsort()[-5:][::-1]
                
                best_match = None
                best_score = 0

                for j in top_indices:
                    # ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¶Ø¹ÙŠÙØ© Ù†ØµÙŠØ§Ù‹
                    if cosine_sim[i][j] < 0.3: continue
                    
                    row_comp = comp_df.iloc[j]
                    
                    # --- Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ Ø§Ù„ØµØ§Ø±Ù… ---
                    is_valid, _ = self.check_logic_match(row_our, row_comp)
                    if not is_valid: continue

                    # Ø­Ø³Ø§Ø¨ Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ø§Ø³Ù…
                    score = fuzz.token_sort_ratio(row_our['clean_name'], row_comp['clean_name'])
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© (Ù„ØªÙØ§Ø¯ÙŠ Ø®Ù…Ø±Ø© vs Ø®Ù…Ø±Ø© Ù‚Ù‡ÙˆØ©)
                    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ ÙƒÙ„Ù…Ø© Ù…Ù‡Ù…Ø© ÙÙŠ Ø£Ø­Ø¯ Ø§Ù„Ø§Ø³Ù…ÙŠÙ† ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¢Ø®Ø±ØŒ Ù†Ø¹Ø§Ù‚Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                    w1 = set(row_our['clean_name'].split())
                    w2 = set(row_comp['clean_name'].split())
                    diff_words = w1.symmetric_difference(w2)
                    
                    penalty = 0
                    critical_words = ['intense', 'elixir', 'le parfum', 'qahwa', 'royal', 'sport', 'blue', 'red']
                    for w in diff_words:
                        if w in critical_words or len(w) > 3: # ÙƒÙ„Ù…Ø© Ø·ÙˆÙŠÙ„Ø© Ù…Ø®ØªÙ„ÙØ© = Ù…Ù†ØªØ¬ Ù…Ø®ØªÙ„Ù
                            penalty += 15
                    
                    final_score = score - penalty

                    if final_score > best_score and final_score >= 60: # Ø¹ØªØ¨Ø© Ø§Ù„Ù‚Ø¨ÙˆÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
                        best_score = final_score
                        best_match = row_comp

                if best_match is not None:
                    p_our = float(row_our[self.our_pr])
                    p_comp = float(best_match[comp_data['pr_col']])
                    
                    # ÙÙ„ØªØ± Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø¬Ù†ÙˆÙ† (Ø­Ù…Ø§ÙŠØ© Ø£Ø®ÙŠØ±Ø©)
                    # Ø¥Ø°Ø§ Ø§Ù„Ø³Ø¹Ø± 10 Ø£Ø¶Ø¹Ø§Ù Ø£Ùˆ Ø§Ù„Ø¹ÙƒØ³ØŒ ØºØ§Ù„Ø¨Ø§Ù‹ Ø®Ø·Ø£ (Ø·Ù‚Ù… vs Ø¹ÙŠÙ†Ø©)
                    if p_comp > 0 and (p_our / p_comp > 5 or p_comp / p_our > 5):
                        decision = "âš ï¸ ØªØ­Ù‚Ù‚ Ø³Ø¹Ø±"
                    else:
                        diff = p_our - p_comp
                        if diff > 10: decision = "ğŸ”´ Ø³Ø¹Ø± Ø£Ø¹Ù„Ù‰"
                        elif diff < -10: decision = "ğŸŸ¢ Ø³Ø¹Ø± Ø£Ù‚Ù„"
                        else: decision = "âœ… Ù…ÙˆØ§ÙÙ‚"

                    results.append({
                        "Ø§Ù„Ù…Ù†ØªØ¬": row_our[self.our_p],
                        "Ø§Ù„Ø³Ø¹Ø±": p_our,
                        "Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„Ù…Ù†ØªØ¬": row_our['nature'], # Ù„Ù„ØªÙˆØ¶ÙŠØ­
                        "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³": best_match[comp_data['p_col']],
                        "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³": p_comp,
                        "Ø§Ù„ÙØ±Ù‚": diff if 'diff' in locals() else 0,
                        "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚": best_score,
                        "Ø§Ù„Ù‚Ø±Ø§Ø±": decision,
                        "Ø§Ù„Ù…Ù†Ø§ÙØ³": comp_name
                    })

                if progress_callback and i % 50 == 0: progress_callback(i/total)

        if not results: return pd.DataFrame()
        
        # ØªØµÙÙŠØ© Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©
        df_res = pd.DataFrame(results)
        final_rows = []
        for n, g in df_res.groupby("Ø§Ù„Ù…Ù†ØªØ¬"):
            best = g.sort_values(by=['Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚', 'Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³'], ascending=[False, True]).iloc[0].to_dict()
            final_rows.append(best)
            
        return pd.DataFrame(final_rows)

# ===== ÙˆØ§Ø¬Ù‡Ø§Øª =====
def read_file(uploaded_file):
    import io
    uploaded_file.seek(0)
    name = uploaded_file.name.lower()
    df = None
    if name.endswith('.csv'):
        try: df = pd.read_csv(uploaded_file, encoding='utf-8')
        except: 
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding='cp1256') # Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    elif name.endswith(('.xlsx', '.xls')):
        try: df = pd.read_excel(uploaded_file)
        except: pass
    
    if df is not None:
        df.columns = df.columns.str.strip()
        df = df.dropna(how='all')
    return df, None

def run_full_analysis(our_df, comp_dfs, progress_callback=None, mapping=None):
    matcher = StrictMatcher(our_df, comp_dfs, mapping)
    return matcher.run(progress_callback)

def find_missing_products(our_df, comp_dfs): return pd.DataFrame() # Ù…Ø¨Ø³Ø· Ù„Ù„Ø¢Ù†
def export_excel(df, sheet_name="Sheet1"):
    import io
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as w:
        df.to_excel(w, sheet_name=sheet_name[:30], index=False)
    return output.getvalue()
def export_section_excel(df, name): return export_excel(df, name)
