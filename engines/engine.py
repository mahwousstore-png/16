"""
engine.py - Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø°ÙƒÙŠ v16.0
Ø®ÙÙŠÙ | Ø³Ø±ÙŠØ¹ | Ø¯Ù‚ÙŠÙ‚
"""
import re, pandas as pd, numpy as np
from rapidfuzz import fuzz, process
from io import BytesIO
from config import (MATCH_THRESHOLD, HIGH_CONFIDENCE, REVIEW_THRESHOLD,
                    PRICE_TOLERANCE, REJECT_KEYWORDS, TESTER_KEYWORDS,
                    SET_KEYWORDS, KNOWN_BRANDS, WORD_REPLACEMENTS)


# ===== ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ =====
def normalize_name(name):
    if not isinstance(name, str): return ""
    t = name.strip().lower()
    for ar, en in WORD_REPLACEMENTS.items():
        t = t.replace(ar, en)
    t = re.sub(r'[^\w\s]', ' ', t)
    t = re.sub(r'\s+', ' ', t).strip()
    return t


def extract_size(name):
    if not isinstance(name, str): return 0
    m = re.findall(r'(\d+(?:\.\d+)?)\s*(?:ml|Ù…Ù„|Ù…Ù„ÙŠ)', name.lower())
    return float(m[-1]) if m else 0


def extract_brand(name):
    if not isinstance(name, str): return ""
    nl = name.lower()
    for b in KNOWN_BRANDS:
        if b.lower() in nl: return b
    return ""


def classify_product(name):
    if not isinstance(name, str): return "Ø¹Ø§Ø¯ÙŠ"
    nl = name.lower()
    for kw in REJECT_KEYWORDS:
        if kw in nl: return "Ø¹ÙŠÙ†Ø©"
    for kw in TESTER_KEYWORDS:
        if kw in nl: return "ØªØ³ØªØ±"
    for kw in SET_KEYWORDS:
        if kw in nl: return "Ø·Ù‚Ù…"
    return "Ø¹Ø§Ø¯ÙŠ"


def get_type_label(t):
    m = {"Ø¹Ø§Ø¯ÙŠ": "ğŸŸ¢", "ØªØ³ØªØ±": "ğŸŸ¡", "Ø·Ù‚Ù…": "ğŸ“¦", "Ø¹ÙŠÙ†Ø©": "ğŸš«"}
    return m.get(t, "")


def is_sample(name):
    if not isinstance(name, str): return False
    nl = name.lower()
    return any(kw in nl for kw in REJECT_KEYWORDS)


# ===== Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª =====
def read_file(file_data):
    data = file_data["data"]
    name = file_data["name"].lower()
    try:
        if name.endswith(".csv"):
            df = pd.read_csv(BytesIO(data))
        else:
            df = pd.read_excel(BytesIO(data))
    except Exception:
        return pd.DataFrame()
    df.columns = df.columns.str.strip()
    return df


def detect_columns(df):
    name_col = price_col = None
    for c in df.columns:
        cl = c.lower().strip()
        if not name_col and any(k in cl for k in ['Ø§Ø³Ù…','name','Ù…Ù†ØªØ¬','product','Ø¹Ù†ÙˆØ§Ù†','title']):
            name_col = c
        if not price_col and any(k in cl for k in ['Ø³Ø¹Ø±','price','Ø«Ù…Ù†','cost']):
            price_col = c
    if not name_col and len(df.columns) >= 1:
        name_col = df.columns[0]
    if not price_col and len(df.columns) >= 2:
        for c in df.columns[1:]:
            if df[c].dtype in ['float64','int64']:
                price_col = c
                break
    return name_col, price_col


# ===== Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø°ÙƒÙŠØ© =====
def smart_match(our_name, comp_names, threshold=MATCH_THRESHOLD):
    if not our_name or not comp_names:
        return None, 0, -1
    our_norm = normalize_name(our_name)
    our_size = extract_size(our_name)
    our_brand = extract_brand(our_name).lower()
    our_type = classify_product(our_name)

    best_score = 0
    best_name = None
    best_idx = -1

    for i, cn in enumerate(comp_names):
        cn_norm = normalize_name(cn)
        cn_size = extract_size(cn)
        cn_brand = extract_brand(cn).lower()
        cn_type = classify_product(cn)

        # ØªØ®Ø·ÙŠ Ø¥Ø°Ø§ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„ÙØ© Ø¬Ø¯Ø§Ù‹
        if our_type != cn_type:
            continue

        # ØªØ®Ø·ÙŠ Ø¥Ø°Ø§ Ø§Ù„Ø£Ø­Ø¬Ø§Ù… Ù…Ø®ØªÙ„ÙØ©
        if our_size > 0 and cn_size > 0 and our_size != cn_size:
            continue

        # ØªØ®Ø·ÙŠ Ø¥Ø°Ø§ Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ù…Ø®ØªÙ„ÙØ©
        if our_brand and cn_brand and our_brand != cn_brand:
            continue

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
        s1 = fuzz.token_sort_ratio(our_norm, cn_norm)
        s2 = fuzz.token_set_ratio(our_norm, cn_norm)
        s3 = fuzz.partial_ratio(our_norm, cn_norm)
        score = max(s1, s2, int(s3 * 0.9))

        # Ù…ÙƒØ§ÙØ£Ø© ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø§Ø±ÙƒØ©
        if our_brand and our_brand == cn_brand:
            score = min(100, score + 5)

        # Ù…ÙƒØ§ÙØ£Ø© ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø­Ø¬Ù…
        if our_size > 0 and our_size == cn_size:
            score = min(100, score + 5)

        if score > best_score:
            best_score = score
            best_name = cn
            best_idx = i

    if best_score >= threshold:
        return best_name, best_score, best_idx
    return None, best_score, -1


# ===== Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ =====
def run_full_analysis(my_file_data, comp_files_data, threshold=MATCH_THRESHOLD, progress_cb=None):
    try:
        if progress_cb: progress_cb(10, "ğŸ“‚ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…ØªØ¬Ø±...")
        my_df = read_file(my_file_data)
        if my_df.empty:
            return {"error": "Ù…Ù„Ù Ø§Ù„Ù…ØªØ¬Ø± ÙØ§Ø±Øº Ø£Ùˆ ØºÙŠØ± ØµØ§Ù„Ø­"}

        my_name_col, my_price_col = detect_columns(my_df)
        if not my_name_col:
            return {"error": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ ÙÙŠ Ù…Ù„Ù Ø§Ù„Ù…ØªØ¬Ø±"}

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†
        if progress_cb: progress_cb(20, "ğŸ“‚ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†...")
        all_comp = []
        for cf in comp_files_data:
            cdf = read_file(cf)
            if cdf.empty: continue
            cn, cp = detect_columns(cdf)
            if not cn: continue
            comp_name = cf["name"].replace(".xlsx","").replace(".csv","").replace("_"," ")
            for _, row in cdf.iterrows():
                pname = str(row.get(cn, "")).strip()
                if not pname: continue
                price = 0
                if cp:
                    try: price = float(row[cp])
                    except: price = 0
                all_comp.append({"name": pname, "price": price, "source": comp_name})

        if not all_comp:
            return {"error": "Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ† ÙØ§Ø±ØºØ©"}

        comp_names = [c["name"] for c in all_comp]

        # Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        results_raise = []
        results_lower = []
        results_approved = []
        results_missing = []
        results_review = []
        all_results = []

        total = len(my_df)
        if progress_cb: progress_cb(30, f"ğŸ” Ù…Ø·Ø§Ø¨Ù‚Ø© {total} Ù…Ù†ØªØ¬...")

        for idx, row in my_df.iterrows():
            pname = str(row.get(my_name_col, "")).strip()
            if not pname: continue

            # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙÙ‚Ø·
            if is_sample(pname):
                continue

            our_price = 0
            if my_price_col:
                try: our_price = float(row[my_price_col])
                except: our_price = 0

            ptype = classify_product(pname)
            psize = extract_size(pname)
            pbrand = extract_brand(pname)

            match_name, match_score, match_idx = smart_match(pname, comp_names, threshold)

            if match_name and match_idx >= 0:
                comp = all_comp[match_idx]
                comp_price = comp["price"]
                diff = our_price - comp_price
                pct = (diff / comp_price * 100) if comp_price > 0 else 0

                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø®Ø·ÙˆØ±Ø©
                if abs(diff) > 50: risk = "Ø­Ø±Ø¬"
                elif abs(diff) > 20: risk = "Ù…ØªÙˆØ³Ø·"
                else: risk = "Ù…Ù†Ø®ÙØ¶"

                # ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø§Ø±
                if diff > PRICE_TOLERANCE:
                    decision = "Ø±ÙØ¹ Ø³Ø¹Ø±"
                    reason = f"Ø³Ø¹Ø±Ù†Ø§ Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙØ³ Ø¨Ù€ {diff:.0f} Ø±.Ø³ ({pct:.1f}%)"
                elif diff < -PRICE_TOLERANCE:
                    decision = "Ø®ÙØ¶ Ø³Ø¹Ø±"
                    reason = f"Ø³Ø¹Ø±Ù†Ø§ Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙØ³ Ø¨Ù€ {abs(diff):.0f} Ø±.Ø³ ({abs(pct):.1f}%)"
                else:
                    decision = "Ù…ÙˆØ§ÙÙ‚"
                    reason = f"Ø§Ù„ÙØ±Ù‚ Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ ({diff:+.0f} Ø±.Ø³)"

                rec = {
                    "Ø§Ù„Ù…Ù†ØªØ¬": pname,
                    "Ø§Ù„Ø³Ø¹Ø±": our_price,
                    "Ø§Ø³Ù… Ø§Ù„Ù…Ù†Ø§ÙØ³": match_name,
                    "Ø£Ù‚Ù„ Ø³Ø¹Ø± Ù…Ù†Ø§ÙØ³": comp_price,
                    "Ø§Ù„ÙØ±Ù‚": diff,
                    "Ø§Ù„Ù†Ø³Ø¨Ø©": round(pct, 1),
                    "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚": match_score,
                    "Ø§Ù„Ù…Ù†Ø§ÙØ³": comp["source"],
                    "Ø§Ù„Ù†ÙˆØ¹": ptype,
                    "Ø§Ù„Ø­Ø¬Ù…": psize,
                    "Ø§Ù„Ù…Ø§Ø±ÙƒØ©": pbrand,
                    "Ø§Ù„Ø®Ø·ÙˆØ±Ø©": risk,
                    "Ø§Ù„Ù‚Ø±Ø§Ø±": decision,
                    "Ø§Ù„ØªÙØ³ÙŠØ±": reason,
                }

                all_results.append(rec)

                if match_score < REVIEW_THRESHOLD:
                    results_review.append(rec)
                elif decision == "Ø±ÙØ¹ Ø³Ø¹Ø±":
                    results_raise.append(rec)
                elif decision == "Ø®ÙØ¶ Ø³Ø¹Ø±":
                    results_lower.append(rec)
                else:
                    results_approved.append(rec)
            else:
                # Ù„Ù… ÙŠØªÙ… Ø¥ÙŠØ¬Ø§Ø¯ Ù…Ø·Ø§Ø¨Ù‚Ø© â†’ Ù…ÙÙ‚ÙˆØ¯ Ø¹Ù†Ø¯ Ø§Ù„Ù…Ù†Ø§ÙØ³
                pass

            if progress_cb and idx % 50 == 0:
                pct_done = 30 + int((idx / max(total, 1)) * 50)
                progress_cb(pct_done, f"ğŸ” ØªØ­Ù„ÙŠÙ„ {idx}/{total}...")

        # Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¹Ù†Ø¯ Ø§Ù„Ù…Ù†Ø§ÙØ³ ÙˆÙ„ÙŠØ³Øª Ø¹Ù†Ø¯Ù†Ø§)
        if progress_cb: progress_cb(82, "ğŸ“‹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©...")
        my_names = [str(row.get(my_name_col, "")).strip().lower() for _, row in my_df.iterrows()]
        for comp in all_comp:
            if is_sample(comp["name"]): continue
            cn_norm = normalize_name(comp["name"])
            found = False
            for mn in my_names:
                if fuzz.token_sort_ratio(cn_norm, normalize_name(mn)) >= threshold:
                    found = True
                    break
            if not found:
                results_missing.append({
                    "Ø§Ù„Ù…Ù†ØªØ¬": comp["name"],
                    "Ø§Ù„Ø³Ø¹Ø±": comp["price"],
                    "Ø§Ù„Ù…Ù†Ø§ÙØ³": comp["source"],
                    "Ø§Ù„Ù†ÙˆØ¹": classify_product(comp["name"]),
                    "Ø§Ù„Ø­Ø¬Ù…": extract_size(comp["name"]),
                    "Ø§Ù„Ù…Ø§Ø±ÙƒØ©": extract_brand(comp["name"]),
                })

        if progress_cb: progress_cb(90, "ğŸ“Š ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†ØªØ§Ø¦Ø¬...")

        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ DataFrames
        df_raise = pd.DataFrame(results_raise)
        df_lower = pd.DataFrame(results_lower)
        df_approved = pd.DataFrame(results_approved)
        df_missing = pd.DataFrame(results_missing)
        df_review = pd.DataFrame(results_review)
        df_all = pd.DataFrame(all_results)

        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ÙØ±Ù‚
        if not df_raise.empty:
            df_raise = df_raise.sort_values("Ø§Ù„ÙØ±Ù‚", ascending=False)
        if not df_lower.empty:
            df_lower = df_lower.sort_values("Ø§Ù„ÙØ±Ù‚", ascending=True)

        stats = {
            "total": len(all_results),
            "raise_count": len(results_raise),
            "lower_count": len(results_lower),
            "approved_count": len(results_approved),
            "missing_count": len(results_missing),
            "review_count": len(results_review),
            "critical": len([r for r in all_results if r.get("Ø§Ù„Ø®Ø·ÙˆØ±Ø©") == "Ø­Ø±Ø¬"]),
            "avg_diff": np.mean([r["Ø§Ù„ÙØ±Ù‚"] for r in all_results]) if all_results else 0,
            "competitors": len(comp_files_data),
            "threshold": threshold,
            "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M"),
        }

        return {
            "raise": df_raise, "lower": df_lower, "approved": df_approved,
            "missing": df_missing, "review": df_review, "all": df_all,
            "stats": stats,
        }

    except Exception as e:
        return {"error": str(e)}


def export_excel(results):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as w:
        for key, label in [("raise","Ø±ÙØ¹ Ø³Ø¹Ø±"),("lower","Ø®ÙØ¶ Ø³Ø¹Ø±"),("approved","Ù…ÙˆØ§ÙÙ‚"),("missing","Ù…ÙÙ‚ÙˆØ¯Ø©"),("review","Ù…Ø±Ø§Ø¬Ø¹Ø©")]:
            df = results.get(key, pd.DataFrame())
            if not df.empty:
                df.to_excel(w, sheet_name=label, index=False)
    return output.getvalue()
