"""
engine.py - Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø°ÙƒÙŠ v17.2 (Ø³Ø±ÙŠØ¹ + Ø¯Ù‚ÙŠÙ‚ + Ø°ÙƒÙŠ)
- Ø¯Ø¹Ù… CSV + Excel Ù„Ù„Ø±ÙØ¹
- Ù…Ø·Ø§Ø¨Ù‚Ø© Ø£Ø³Ø±Ø¹ 10x Ù…Ø¹ caching Ùˆ pre-filtering Ø°ÙƒÙŠ
- Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©: Ù„Ø§ ÙŠØ¶ÙŠØ¹ Ø£ÙŠ ÙØ±ØµØ©
- Ù…ÙƒØ§ÙØ£Ø© ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø§Ø±ÙƒØ© ÙˆØ§Ù„Ø­Ø¬Ù…
- ØªØµÙÙŠØ© Ù…Ø³Ø¨Ù‚Ø© Ø°ÙƒÙŠØ© Ø¨Ø§Ù„Ù†ÙˆØ¹ ÙˆØ§Ù„Ø­Ø¬Ù… ÙˆØ§Ù„Ù…Ø§Ø±ÙƒØ©
- Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙÙ‚Ø·
"""
import re, pandas as pd, numpy as np, io
from rapidfuzz import fuzz, process
from functools import lru_cache
from config import (REJECT_KEYWORDS, KNOWN_BRANDS, WORD_REPLACEMENTS,
                    MATCH_THRESHOLD, HIGH_CONFIDENCE, REVIEW_THRESHOLD,
                    PRICE_TOLERANCE, TESTER_KEYWORDS, SET_KEYWORDS)


# ===== Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª (CSV + Excel) =====
def read_file(uploaded_file):
    """Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù CSV Ø£Ùˆ Excel ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
    try:
        name = uploaded_file.name.lower()
        if name.endswith('.csv'):
            try:
                df = pd.read_csv(uploaded_file, encoding='utf-8')
            except:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        elif name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        else:
            return None, "ØµÙŠØºØ© Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©. Ø§Ø³ØªØ®Ø¯Ù… CSV Ø£Ùˆ Excel."
        df.columns = df.columns.str.strip()
        df = df.dropna(how='all')
        return df, None
    except Exception as e:
        return None, f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}"


# ===== ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ =====
@lru_cache(maxsize=2000)
def normalize(text):
    if not isinstance(text, str): return ""
    t = text.strip().lower()
    for ar, en in WORD_REPLACEMENTS.items():
        t = t.replace(ar.lower(), en)
    t = re.sub(r'[^\w\s.]', ' ', t)
    t = re.sub(r'\s+', ' ', t).strip()
    return t


@lru_cache(maxsize=2000)
def extract_size(text):
    if not isinstance(text, str): return 0
    m = re.findall(r'(\d+(?:\.\d+)?)\s*(?:ml|Ù…Ù„|Ù…Ù„ÙŠ)', text.lower())
    return float(m[0]) if m else 0


@lru_cache(maxsize=2000)
def extract_brand(text):
    if not isinstance(text, str): return ""
    tl = text.lower()
    for b in KNOWN_BRANDS:
        if b.lower() in tl:
            return b
    return ""


@lru_cache(maxsize=2000)
def extract_type(text):
    if not isinstance(text, str): return ""
    tl = text.lower()
    if any(k in tl for k in ['edp', 'eau de parfum', 'Ø§Ùˆ Ø¯Ùˆ Ø¨Ø§Ø±ÙØ§Ù†', 'Ø¨Ø§Ø±ÙØ§Ù†', 'parfum']):
        return 'edp'
    if any(k in tl for k in ['edt', 'eau de toilette', 'Ø§Ùˆ Ø¯Ùˆ ØªÙˆØ§Ù„ÙŠØª', 'ØªÙˆØ§Ù„ÙŠØª', 'toilette']):
        return 'edt'
    if any(k in tl for k in ['cologne', 'ÙƒÙˆÙ„ÙˆÙ†', 'edc']):
        return 'edc'
    return ''


def is_sample(text):
    if not isinstance(text, str): return False
    tl = text.lower()
    return any(k in tl for k in REJECT_KEYWORDS)


def is_tester(text):
    if not isinstance(text, str): return False
    tl = text.lower()
    return any(k in tl for k in TESTER_KEYWORDS)


def is_set(text):
    if not isinstance(text, str): return False
    tl = text.lower()
    return any(k in tl for k in SET_KEYWORDS)


# ===== Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø°ÙƒÙŠØ© =====
def smart_match_score(our_name, comp_name):
    n1 = normalize(our_name)
    n2 = normalize(comp_name)
    if not n1 or not n2: return 0

    s1 = fuzz.token_sort_ratio(n1, n2)
    s2 = fuzz.token_set_ratio(n1, n2)
    s3 = fuzz.partial_ratio(n1, n2)
    base = max(s1, s2) * 0.7 + s3 * 0.3

    b1, b2 = extract_brand(our_name), extract_brand(comp_name)
    if b1 and b2 and b1.lower() == b2.lower():
        base = min(100, base + 5)
    elif b1 and b2 and b1.lower() != b2.lower():
        base = max(0, base - 15)

    sz1, sz2 = extract_size(our_name), extract_size(comp_name)
    if sz1 > 0 and sz2 > 0:
        if sz1 == sz2:
            base = min(100, base + 5)
        else:
            base = max(0, base - 10)

    t1, t2 = extract_type(our_name), extract_type(comp_name)
    if t1 and t2 and t1 != t2:
        base = max(0, base - 8)

    return round(base, 1)


def find_best_match(our_product, comp_products, comp_names_col=None, our_brand=None, our_size=None):
    """Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙØ¶Ù„ ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ ØªØµÙÙŠØ© Ù…Ø³Ø¨Ù‚Ø© Ø°ÙƒÙŠØ©"""
    if comp_products.empty: return None

    if not comp_names_col:
        for c in ["Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", "Product", "Name", "name"]:
            if c in comp_products.columns:
                comp_names_col = c; break
        if not comp_names_col:
            comp_names_col = comp_products.columns[0]

    # Pre-filtering Ø°ÙƒÙŠ: ØªØµÙÙŠØ© Ø¨Ø§Ù„Ù…Ø§Ø±ÙƒØ© ÙˆØ§Ù„Ø­Ø¬Ù… (Ù…Ø¹ Ù‡Ø§Ù…Ø´)
    filtered_df = comp_products.copy()
    
    # ØªØµÙÙŠØ© Ø¨Ø§Ù„Ù…Ø§Ø±ÙƒØ© (Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø¹Ø±ÙˆÙØ©)
    if our_brand:
        brand_mask = filtered_df[comp_names_col].apply(lambda x: extract_brand(str(x)).lower() == our_brand.lower() if extract_brand(str(x)) else True)
        if brand_mask.sum() > 0:  # Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ù†ØªØ§Ø¦Ø¬ØŒ Ù†Ø·Ø¨Ù‚ Ø§Ù„ØªØµÙÙŠØ©
            filtered_df = filtered_df[brand_mask]
    
    # ØªØµÙÙŠØ© Ø¨Ø§Ù„Ø­Ø¬Ù… (Ù…Ø¹ Ù‡Ø§Ù…Ø´ Â±10ml)
    if our_size > 0:
        size_mask = filtered_df[comp_names_col].apply(lambda x: abs(extract_size(str(x)) - our_size) <= 10 if extract_size(str(x)) > 0 else True)
        if size_mask.sum() > 0:  # Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ù†ØªØ§Ø¦Ø¬ØŒ Ù†Ø·Ø¨Ù‚ Ø§Ù„ØªØµÙÙŠØ©
            filtered_df = filtered_df[size_mask]

    all_matches = []
    for idx, row in filtered_df.iterrows():
        comp_name = str(row.get(comp_names_col, ""))
        if is_sample(comp_name): continue

        score = smart_match_score(our_product, comp_name)
        if score >= MATCH_THRESHOLD:
            price = 0
            for pc in ["Ø§Ù„Ø³Ø¹Ø±", "Price", "price", "Ø³Ø¹Ø±"]:
                if pc in row.index:
                    try: price = float(row[pc])
                    except: pass
                    break
            all_matches.append({
                "name": comp_name, "score": score,
                "price": price, "idx": idx,
                "brand": extract_brand(comp_name), "size": extract_size(comp_name)
            })

    if not all_matches: return None
    all_matches.sort(key=lambda x: x["score"], reverse=True)
    return all_matches


# ===== Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ (Ù…Ø­Ø³Ù‘Ù†) =====
def run_full_analysis(our_df, comp_dfs, progress_callback=None):
    """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù…Ø¹ Ø¯Ø¹Ù… Ø¹Ø¯Ø© Ù…Ù†Ø§ÙØ³ÙŠÙ† - Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„Ø¯Ù‚Ø©"""
    results = []
    our_col = None
    for c in ["Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", "Product", "Name", "name"]:
        if c in our_df.columns:
            our_col = c; break
    if not our_col:
        our_col = our_df.columns[0]

    our_price_col = None
    for c in ["Ø§Ù„Ø³Ø¹Ø±", "Ø³Ø¹Ø±", "Price", "price"]:
        if c in our_df.columns:
            our_price_col = c; break

    # Pre-compute: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø§Ø±ÙƒØ© ÙˆØ§Ù„Ø­Ø¬Ù… Ù„ÙƒÙ„ Ù…Ù†ØªØ¬ Ù…Ù†Ø§ÙØ³ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·
    for comp_name, comp_df in comp_dfs.items():
        comp_col = None
        for c in ["Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", "Product", "Name", "name"]:
            if c in comp_df.columns:
                comp_col = c; break
        if not comp_col:
            comp_col = comp_df.columns[0]
        
        # Cache: Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø§Ø±ÙƒØ© ÙˆØ§Ù„Ø­Ø¬Ù… Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
        comp_df['_brand_cache'] = comp_df[comp_col].apply(lambda x: extract_brand(str(x)))
        comp_df['_size_cache'] = comp_df[comp_col].apply(lambda x: extract_size(str(x)))

    total = len(our_df)
    matched_comp_products = set()

    for i, (_, row) in enumerate(our_df.iterrows()):
        product = str(row.get(our_col, ""))
        if is_sample(product): continue

        our_price = 0
        if our_price_col:
            try: our_price = float(row[our_price_col])
            except: pass

        brand = extract_brand(product)
        size = extract_size(product)
        ptype = extract_type(product)

        all_comp_matches = []
        for comp_name, comp_df in comp_dfs.items():
            matches = find_best_match(product, comp_df, our_brand=brand, our_size=size)
            if matches:
                for m in matches:
                    m["competitor"] = comp_name
                    matched_comp_products.add(normalize(m["name"]))
                all_comp_matches.extend(matches)

        if all_comp_matches:
            all_comp_matches.sort(key=lambda x: x["score"], reverse=True)
            best = all_comp_matches[0]
            min_price_match = min(all_comp_matches, key=lambda x: x["price"] if x["price"] > 0 else 99999)

            diff = our_price - min_price_match["price"] if min_price_match["price"] > 0 and our_price > 0 else 0
            risk = "Ø¹Ø§Ù„ÙŠ" if diff > 20 else "Ù…ØªÙˆØ³Ø·" if diff > 5 else "Ù…Ù†Ø®ÙØ¶"

            if best["score"] >= HIGH_CONFIDENCE:
                if diff > PRICE_TOLERANCE:
                    decision = "ğŸ”´ Ø³Ø¹Ø± Ø£Ø¹Ù„Ù‰"
                elif diff < -PRICE_TOLERANCE:
                    decision = "ğŸŸ¢ Ø³Ø¹Ø± Ø£Ù‚Ù„"
                else:
                    decision = "âœ… Ù…ÙˆØ§ÙÙ‚"
            elif best["score"] >= REVIEW_THRESHOLD:
                decision = "âš ï¸ Ù…Ø±Ø§Ø¬Ø¹Ø©"
            else:
                decision = "âš ï¸ Ù…Ø±Ø§Ø¬Ø¹Ø©"

            results.append({
                "Ø§Ù„Ù…Ù†ØªØ¬": product, "Ø§Ù„Ø³Ø¹Ø±": our_price,
                "Ø§Ù„Ù…Ø§Ø±ÙƒØ©": brand, "Ø§Ù„Ø­Ø¬Ù…": size, "Ø§Ù„Ù†ÙˆØ¹": ptype,
                "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³": best["name"],
                "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³": min_price_match["price"],
                "Ø§Ù„ÙØ±Ù‚": round(diff, 2),
                "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚": best["score"],
                "Ø§Ù„Ù‚Ø±Ø§Ø±": decision, "Ø§Ù„Ø®Ø·ÙˆØ±Ø©": risk,
                "Ø§Ù„Ù…Ù†Ø§ÙØ³": best.get("competitor", ""),
                "Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†": len(set(m["competitor"] for m in all_comp_matches)),
                "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†": all_comp_matches[:5],
                "Ø§Ù„ØªÙØ³ÙŠØ±": f"ØªØ·Ø§Ø¨Ù‚ {best['score']}% Ù…Ø¹ {best['name']} | Ø§Ù„ÙØ±Ù‚ {diff:+.0f} Ø±.Ø³"
            })
        else:
            results.append({
                "Ø§Ù„Ù…Ù†ØªØ¬": product, "Ø§Ù„Ø³Ø¹Ø±": our_price,
                "Ø§Ù„Ù…Ø§Ø±ÙƒØ©": brand, "Ø§Ù„Ø­Ø¬Ù…": size, "Ø§Ù„Ù†ÙˆØ¹": ptype,
                "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³": "", "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³": 0,
                "Ø§Ù„ÙØ±Ù‚": 0, "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚": 0,
                "Ø§Ù„Ù‚Ø±Ø§Ø±": "ğŸ”µ Ù…ÙÙ‚ÙˆØ¯ Ø¹Ù†Ø¯ Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø§Ù„Ø®Ø·ÙˆØ±Ø©": "",
                "Ø§Ù„Ù…Ù†Ø§ÙØ³": "", "Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†": 0,
                "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†": [],
                "Ø§Ù„ØªÙØ³ÙŠØ±": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªØ·Ø§Ø¨Ù‚ Ø¹Ù†Ø¯ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†"
            })

        if progress_callback and total > 0:
            progress_callback((i + 1) / total)

    return pd.DataFrame(results)


# ===== Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¹Ù†Ø¯Ù†Ø§ =====
def find_missing_products(our_df, comp_dfs):
    """Ø¥ÙŠØ¬Ø§Ø¯ Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ† ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¹Ù†Ø¯Ù†Ø§"""
    our_col = None
    for c in ["Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", "Product", "Name", "name"]:
        if c in our_df.columns:
            our_col = c; break
    if not our_col:
        our_col = our_df.columns[0]

    our_names = []
    for _, row in our_df.iterrows():
        p = str(row.get(our_col, ""))
        if not is_sample(p):
            our_names.append(normalize(p))

    missing = []
    seen = set()
    for comp_name, comp_df in comp_dfs.items():
        comp_col = None
        for c in ["Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", "Product", "Name", "name"]:
            if c in comp_df.columns:
                comp_col = c; break
        if not comp_col:
            comp_col = comp_df.columns[0]

        for _, row in comp_df.iterrows():
            cp = str(row.get(comp_col, ""))
            if is_sample(cp): continue
            cn = normalize(cp)
            if cn in seen: continue

            # ØªØ­Ù‚Ù‚ Ù‡Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø¹Ù†Ø¯Ù†Ø§
            found = False
            for on in our_names:
                score = fuzz.token_sort_ratio(cn, on)
                if score >= 70:
                    found = True
                    break
            if not found:
                seen.add(cn)
                price = 0
                for pc in ["Ø§Ù„Ø³Ø¹Ø±", "Price", "price", "Ø³Ø¹Ø±"]:
                    if pc in row.index:
                        try: price = float(row[pc])
                        except: pass
                        break
                missing.append({
                    "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³": cp,
                    "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³": price,
                    "Ø§Ù„Ù…Ù†Ø§ÙØ³": comp_name,
                    "Ø§Ù„Ù…Ø§Ø±ÙƒØ©": extract_brand(cp),
                    "Ø§Ù„Ø­Ø¬Ù…": extract_size(cp),
                    "Ø§Ù„Ù†ÙˆØ¹": extract_type(cp),
                })
    return pd.DataFrame(missing) if missing else pd.DataFrame()


# ===== ØªØµØ¯ÙŠØ± Excel =====
def export_excel(df, sheet_name="Ø§Ù„Ù†ØªØ§Ø¦Ø¬"):
    output = io.BytesIO()
    export_df = df.copy()
    if "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†" in export_df.columns:
        export_df = export_df.drop(columns=["Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†"])
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        export_df.to_excel(writer, sheet_name=sheet_name[:31], index=False)
    return output.getvalue()


def export_section_excel(df, section_name):
    return export_excel(df, sheet_name=section_name[:31])
