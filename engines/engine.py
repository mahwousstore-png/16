"""
engine.py - Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…ØªØ¬Ù‡ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ v17.3 (Anti-Crash)
- Ø¥ØµÙ„Ø§Ø­ Ø®Ø·Ø£ ImportError Ùˆ KeyError
- ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ TF-IDF Ù„Ø³Ø±Ø¹Ø© 50x
- ÙŠØ¶Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙƒØ§ÙØ© Ø¯ÙˆØ§Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
"""
import re
import pandas as pd
import numpy as np
import io
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
try:
    from config import (
        REJECT_KEYWORDS, KNOWN_BRANDS, WORD_REPLACEMENTS,
        MATCH_THRESHOLD, HIGH_CONFIDENCE, REVIEW_THRESHOLD,
        PRICE_TOLERANCE, TESTER_KEYWORDS, SET_KEYWORDS
    )
except ImportError:
    MATCH_THRESHOLD = 60
    HIGH_CONFIDENCE = 90
    PRICE_TOLERANCE = 5
    REJECT_KEYWORDS = ["sample", "Ø¹ÙŠÙ†Ø©"]
    KNOWN_BRANDS = []
    WORD_REPLACEMENTS = {}

# ===== 1. Ø¯ÙˆØ§Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Helpers) =====

def read_file(uploaded_file):
    """Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù CSV Ø£Ùˆ Excel Ø¨Ù…Ø±ÙˆÙ†Ø© Ø¹Ø§Ù„ÙŠØ©"""
    try:
        name = uploaded_file.name.lower()
        if name.endswith('.csv'):
            try:
                df = pd.read_csv(uploaded_file, encoding='utf-8')
            except:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        elif name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        else:
            return None, "ØµÙŠØºØ© Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©"
        
        df.columns = df.columns.str.strip()
        df = df.dropna(how='all')
        return df, None
    except Exception as e:
        return None, f"Ø®Ø·Ø£ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©: {str(e)}"

def normalize(text):
    """ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ"""
    if not isinstance(text, str): return ""
    t = text.strip().lower()
    for ar, en in WORD_REPLACEMENTS.items():
        t = t.replace(ar.lower(), en)
    t = re.sub("[Ø¥Ø£Ø¢Ø§]", "Ø§", t)
    t = re.sub("Ø©", "Ù‡", t)
    t = re.sub("Ù‰", "ÙŠ", t)
    t = re.sub(r'[^\w\s.]', ' ', t)
    t = re.sub(r'\s+', ' ', t).strip()
    return t

def extract_size(text):
    if not isinstance(text, str): return 0
    m = re.findall(r'(\d+(?:\.\d+)?)\s*(?:ml|Ù…Ù„|Ù…Ù„ÙŠ|g|Øº)', text.lower())
    return float(m[0]) if m else 0

def extract_brand(text):
    if not isinstance(text, str): return ""
    tl = text.lower()
    for b in KNOWN_BRANDS:
        if b.lower() in tl:
            return b
    return text.split()[0] if text else ""

def extract_type(text):
    if not isinstance(text, str): return ""
    tl = text.lower()
    if any(k in tl for k in ['edp', 'eau de parfum', 'Ø¨Ø§Ø±ÙÙŠÙˆÙ…', 'parfum']): return 'EDP'
    if any(k in tl for k in ['edt', 'eau de toilette', 'ØªÙˆØ§Ù„ÙŠØª']): return 'EDT'
    if any(k in tl for k in ['cologne', 'ÙƒÙˆÙ„ÙˆÙ†', 'edc']): return 'EDC'
    if any(k in tl for k in ['oil', 'Ø²ÙŠØª']): return 'Oil'
    return ''

def is_sample(text):
    if not isinstance(text, str): return False
    tl = text.lower()
    return any(k in tl for k in REJECT_KEYWORDS)

# ===== 2. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…ØªØ¬Ù‡ÙŠ (Vectorized Engine) =====

def run_full_analysis(our_df, comp_dfs, progress_callback=None):
    """
    ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ Ø³Ø±ÙŠØ¹ Ù…Ø¹ Ø­Ù…Ø§ÙŠØ© Ø¶Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ§Ø±ØºØ©
    """
    results = []
    
    # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø«Ø§Ø¨Øª Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø§Ù„Ø­Ù„ Ù„Ù„Ù…Ø´ÙƒÙ„Ø©)
    columns_structure = [
        "Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ù„Ø³Ø¹Ø±", "Ø§Ù„Ù…Ø§Ø±ÙƒØ©", "Ø§Ù„Ø­Ø¬Ù…", "Ø§Ù„Ù†ÙˆØ¹",
        "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø§Ù„ÙØ±Ù‚", "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚",
        "Ø§Ù„Ù‚Ø±Ø§Ø±", "Ø§Ù„Ø®Ø·ÙˆØ±Ø©", "Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†"
    ]

    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª
    if our_df is None or our_df.empty:
        return pd.DataFrame(columns=columns_structure)

    # ØªØ­Ø¯ÙŠØ¯ Ø£Ø¹Ù…Ø¯ØªÙ†Ø§
    our_col = next((c for c in ["Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", "Product", "Name", "name"] if c in our_df.columns), our_df.columns[0])
    our_price_col = next((c for c in ["Ø§Ù„Ø³Ø¹Ø±", "Ø³Ø¹Ø±", "Price", "price", "Cost"] if c in our_df.columns), None)

    # ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§ØªÙ†Ø§
    our_data = our_df.copy()
    our_data['normalized'] = our_data[our_col].apply(normalize)
    our_data['brand'] = our_data[our_col].apply(extract_brand)
    our_data['size'] = our_data[our_col].apply(extract_size)
    our_data = our_data[~our_data[our_col].apply(is_sample)]

    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­Ø±Ùƒ
    vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=1)
    
    try:
        our_vectors = vectorizer.fit_transform(our_data['normalized'].fillna(""))
    except ValueError:
        return pd.DataFrame(columns=columns_structure)

    total_steps = len(comp_dfs)
    
    for idx, (comp_name, comp_df) in enumerate(comp_dfs.items()):
        if progress_callback: progress_callback((idx) / total_steps)
        
        comp_prod_col = next((c for c in ["Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", "Product", "Name", "name"] if c in comp_df.columns), comp_df.columns[0])
        comp_price_col = next((c for c in ["Ø§Ù„Ø³Ø¹Ø±", "Ø³Ø¹Ø±", "Price", "price"] if c in comp_df.columns), None)

        comp_data = comp_df.copy()
        comp_data = comp_data[~comp_data[comp_prod_col].apply(is_sample)]
        comp_data['normalized'] = comp_data[comp_prod_col].apply(normalize)
        comp_data['brand'] = comp_data[comp_prod_col].apply(extract_brand)
        comp_data['size'] = comp_data[comp_prod_col].apply(extract_size)

        if comp_data.empty: continue

        try:
            comp_vectors = vectorizer.transform(comp_data['normalized'].fillna(""))
        except: continue

        similarity_matrix = cosine_similarity(our_vectors, comp_vectors)

        for i, (our_idx, our_row) in enumerate(our_data.iterrows()):
            sim_scores = similarity_matrix[i]
            
            # Brand Filter
            if our_row['brand']:
                brand_mask = comp_data['brand'].str.lower() != our_row['brand'].lower()
                sim_scores[brand_mask.values] = 0

            # Size Filter
            if our_row['size'] > 0:
                size_diff = np.abs(comp_data['size'].values - our_row['size'])
                size_mask = size_diff > 5
                sim_scores[size_mask] *= 0.5

            best_match_idx = sim_scores.argmax()
            best_score = sim_scores[best_match_idx] * 100

            if best_score >= MATCH_THRESHOLD:
                comp_row = comp_data.iloc[best_match_idx]
                
                our_p = float(our_row[our_price_col]) if our_price_col else 0
                comp_p = float(comp_row[comp_price_col]) if comp_price_col else 0
                
                if our_p <= 1 or comp_p <= 1: continue

                diff = our_p - comp_p
                
                decision = "âœ… Ù…ÙˆØ§ÙÙ‚"
                risk = "Ù…Ù†Ø®ÙØ¶"
                
                if diff > PRICE_TOLERANCE:
                    decision = "ðŸ”´ Ø³Ø¹Ø± Ø£Ø¹Ù„Ù‰"
                    risk = "Ø¹Ø§Ù„ÙŠ"
                elif diff < -PRICE_TOLERANCE:
                    decision = "ðŸŸ¢ Ø³Ø¹Ø± Ø£Ù‚Ù„"
                
                if best_score < HIGH_CONFIDENCE:
                    decision = "âš ï¸ Ù…Ø±Ø§Ø¬Ø¹Ø©"
                    risk = "Ù…ØªÙˆØ³Ø·"

                results.append({
                    "Ø§Ù„Ù…Ù†ØªØ¬": our_row[our_col],
                    "Ø§Ù„Ø³Ø¹Ø±": our_p,
                    "Ø§Ù„Ù…Ø§Ø±ÙƒØ©": our_row['brand'],
                    "Ø§Ù„Ø­Ø¬Ù…": f"{int(our_row['size'])}ml" if our_row['size'] else "",
                    "Ø§Ù„Ù†ÙˆØ¹": extract_type(our_row[our_col]),
                    "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³": comp_row[comp_prod_col],
                    "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³": comp_p,
                    "Ø§Ù„ÙØ±Ù‚": round(diff, 2),
                    "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚": round(best_score, 1),
                    "Ø§Ù„Ù‚Ø±Ø§Ø±": decision,
                    "Ø§Ù„Ø®Ø·ÙˆØ±Ø©": risk,
                    "Ø§Ù„Ù…Ù†Ø§ÙØ³": comp_name,
                    "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†": []
                })

    if progress_callback: progress_callback(1.0)
    
    # === Ù†Ù‚Ø·Ø© Ø§Ù„Ø¥ØµÙ„Ø§Ø­ ===
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙØ§Ø±ØºØ©ØŒ Ù†Ø±Ø¬Ø¹ Ø¬Ø¯ÙˆÙ„Ø§Ù‹ ÙØ§Ø±ØºØ§Ù‹ Ù„ÙƒÙ† Ø¨Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ØµØ­ÙŠØ­Ø©
    if not results:
        return pd.DataFrame(columns=columns_structure)
        
    return pd.DataFrame(results)


def find_missing_products(our_df, comp_dfs):
    """Ù†Ø³Ø®Ø© Ø³Ø±ÙŠØ¹Ø© Ù„Ù„Ù…ÙÙ‚ÙˆØ¯Ø§Øª"""
    missing = []
    
    our_col = next((c for c in ["Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", "Product", "Name", "name"] if c in our_df.columns), our_df.columns[0])
    our_fingerprints = set(our_df[our_col].astype(str).apply(normalize).tolist())
    
    for comp_name, comp_df in comp_dfs.items():
        comp_prod_col = next((c for c in ["Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", "Product", "Name", "name"] if c in comp_df.columns), comp_df.columns[0])
        comp_price_col = next((c for c in ["Ø§Ù„Ø³Ø¹Ø±", "Ø³Ø¹Ø±", "Price", "price"] if c in comp_df.columns), None)
        
        for _, row in comp_df.iterrows():
            p_name = str(row[comp_prod_col])
            if is_sample(p_name): continue
            
            p_fingerprint = normalize(p_name)
            
            if p_fingerprint not in our_fingerprints:
                if len(p_fingerprint) < 4: continue
                
                price = 0
                if comp_price_col:
                    try: price = float(row[comp_price_col])
                    except: pass
                
                missing.append({
                    "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³": p_name,
                    "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³": price,
                    "Ø§Ù„Ù…Ù†Ø§ÙØ³": comp_name,
                    "Ø§Ù„Ù…Ø§Ø±ÙƒØ©": extract_brand(p_name),
                    "Ø§Ù„Ù†ÙˆØ¹": extract_type(p_name),
                    "Ø§Ù„Ø­Ø¬Ù…": extract_size(p_name)
                })

    return pd.DataFrame(missing)


def export_excel(df, sheet_name="Ø§Ù„Ù†ØªØ§Ø¦Ø¬"):
    output = io.BytesIO()
    export_df = df.copy()
    if "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†" in export_df.columns:
        export_df = export_df.drop(columns=["Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†"])
        
    cols_order = ["Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ù„Ø³Ø¹Ø±", "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø§Ù„ÙØ±Ù‚", "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚", "Ø§Ù„Ù‚Ø±Ø§Ø±", "Ø§Ù„Ù…Ù†Ø§ÙØ³", "Ø§Ù„Ù…Ø§Ø±ÙƒØ©"]
    available_cols = [c for c in cols_order if c in export_df.columns]
    remaining_cols = [c for c in export_df.columns if c not in cols_order]
    
    if available_cols:
        export_df = export_df[available_cols + remaining_cols]
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        export_df.to_excel(writer, sheet_name=sheet_name[:31], index=False)
    return output.getvalue()

def export_section_excel(df, section_name):
    return export_excel(df, sheet_name=section_name[:31])
