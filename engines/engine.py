import re
import pandas as pd
import io
from rapidfuzz import fuzz
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from config import KNOWN_BRANDS, WORD_REPLACEMENTS, MATCH_THRESHOLD

# ==========================================
# Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø©
# ==========================================

def deep_normalize(text):
    if not isinstance(text, str): return ""
    t = text.strip().lower()
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    t = re.sub(r'[Ø£Ø¥Ø¢]', 'Ø§', t)
    t = t.replace('Ø©', 'Ù‡').replace('Ù‰', 'ÙŠ')
    # Ø¥Ø¨Ù‚Ø§Ø¡ Ø§Ù„Ø£Ø­Ø±Ù ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… ÙÙ‚Ø·
    t = re.sub(r'[^\w\s.]', ' ', t)
    for ar, en in WORD_REPLACEMENTS.items():
        if ar in t: t = t.replace(ar, en)
    return re.sub(r'\s+', ' ', t).strip()

def get_detailed_dna(text):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø§Ù…Ø¶ Ø§Ù„Ù†ÙˆÙˆÙŠ Ù„Ù„Ù…Ù†ØªØ¬ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„"""
    t = text.lower()
    clean = deep_normalize(text)
    
    # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø¬Ù…
    size_match = re.search(r'\b(\d+)\s*(?:ml|Ù…Ù„|Ù…Ù„ÙŠ|g|gm|gram|Ø¬Ø±Ø§Ù…)\b', t)
    size = int(size_match.group(1)) if size_match else 0
    
    # 2. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹ (Nature)
    nature = "perfume"
    if any(x in t for x in ['set', 'gift', 'Ø·Ù‚Ù…', 'Ù…Ø¬Ù…ÙˆØ¹Ø©', 'Ø¨ÙƒØ¬']): nature = "set"
    elif any(x in t for x in ['hair', 'mist', 'Ø´Ø¹Ø±']): nature = "hair"
    elif any(x in t for x in ['body', 'Ø¬Ø³Ù…', 'Ù„ÙˆØ´Ù†', 'lotion']): nature = "body"
    elif any(x in t for x in ['sample', 'vial', 'Ø¹ÙŠÙ†Ø©']): nature = "sample"
    
    # 3. ÙˆØ³Ù… Ø§Ù„ØªØ³ØªØ±
    is_tester = any(x in t for x in ['tester', 'ØªØ³ØªØ±'])
    
    # 4. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø­Ø±Ø¬Ø© (Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ù„Ù„Ø¥ØµØ¯Ø§Ø±)
    critical_keywords = []
    for word in ['intense', 'elixir', 'parfum', 'qahwa', 'edp', 'edt', 'extreme', 'sport', 'black', 'white', 'rouge']:
        if word in t: critical_keywords.append(word)
        
    # 5. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø§Ø±ÙƒØ©
    brand = "unknown"
    for b in sorted(KNOWN_BRANDS, key=len, reverse=True):
        if b.lower() in t:
            brand = b.lower()
            break
            
    return {
        "brand": brand,
        "size": size,
        "nature": nature,
        "is_tester": is_tester,
        "critical": set(critical_keywords),
        "clean": clean
    }

# ==========================================
# Ù…Ø­Ø±Ùƒ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
# ==========================================

class DeepIntegrityEngine:
    def __init__(self, our_df, comp_dfs, mapping=None):
        self.our_df = our_df.copy()
        self.comp_dfs = comp_dfs
        self.mapping = mapping
        self.prepare_data()

    def prepare_data(self):
        p_col = self.mapping.get('our_name') if self.mapping else self.our_df.columns[1]
        pr_col = self.mapping.get('our_price') if self.mapping else self.our_df.columns[0]
        
        # ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§ØªÙ†Ø§ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
        self.our_df['dna'] = self.our_df[p_col].apply(get_detailed_dna)
        self.our_p, self.our_pr = p_col, pr_col

    def calculate_match_quality(self, dna1, dna2):
        """Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø®Ù…Ø³ Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©"""
        
        # Ø§Ù„Ø·Ø¨Ù‚Ø© 1: Ø§Ù„Ù…Ø§Ø±ÙƒØ© (Ø¥Ø¬Ø¨Ø§Ø±ÙŠ)
        if dna1['brand'] != dna2['brand'] and dna1['brand'] != "unknown" and dna2['brand'] != "unknown":
            return 0, "Ø¥Ø®ØªÙ„Ø§Ù Ù…Ø§Ø±ÙƒØ©"

        # Ø§Ù„Ø·Ø¨Ù‚Ø© 2: Ø§Ù„Ø·Ø¨ÙŠØ¹Ø© (Ø¥Ø¬Ø¨Ø§Ø±ÙŠ)
        if dna1['nature'] != dna2['nature']:
            return 0, "Ø¥Ø®ØªÙ„Ø§Ù Ù†ÙˆØ¹ (Ø¹Ø·Ø± vs Ø·Ù‚Ù…/Ø´Ø¹Ø±)"

        # Ø§Ù„Ø·Ø¨Ù‚Ø© 3: ÙØ­Øµ Ø§Ù„ØªØ³ØªØ±
        if dna1['is_tester'] != dna2['is_tester']:
            return 0, "Ø£Ø­Ø¯Ù‡Ù…Ø§ ØªØ³ØªØ± ÙˆØ§Ù„Ø¢Ø®Ø± Ø£ØµÙ„ÙŠ"

        # Ø§Ù„Ø·Ø¨Ù‚Ø© 4: Ø§Ù„Ø­Ø¬Ù… (ØªÙ†Ø¨ÙŠÙ‡)
        if dna1['size'] > 0 and dna2['size'] > 0 and dna1['size'] != dna2['size']:
            return 0, "Ø¥Ø®ØªÙ„Ø§Ù Ø­Ø¬Ù…"

        # Ø§Ù„Ø·Ø¨Ù‚Ø© 5: Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø­Ø±Ø¬Ø© (Intense, Elixir...)
        # Ø¥Ø°Ø§ ÙˆØ¬Ø¯ Ø¥ØµØ¯Ø§Ø± Ø®Ø§Øµ ÙÙŠ Ø·Ø±Ù ÙˆÙ„Ù… ÙŠÙˆØ¬Ø¯ ÙÙŠ Ø§Ù„Ø¢Ø®Ø±ØŒ Ù†Ø±ÙØ¶ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        if dna1['critical'] != dna2['critical']:
            return 0, "Ø¥Ø®ØªÙ„Ø§Ù Ø¥ØµØ¯Ø§Ø± (Ù…Ø±ÙƒØ²/Ø¹Ø§Ø¯ÙŠ)"

        # Ø¥Ø°Ø§ Ø§Ø¬ØªØ§Ø² ÙƒÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©ØŒ Ù†Ø­Ø³Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù†ØµÙŠ
        score = fuzz.token_sort_ratio(dna1['clean'], dna2['clean'])
        return score, "OK"

    def run(self, progress_callback=None):
        final_results = []
        
        for comp_name, df in self.comp_dfs.items():
            cdf = df.copy()
            cp = self.mapping.get('comp_name') if self.mapping else cdf.columns[0]
            cpr = self.mapping.get('comp_price') if self.mapping else cdf.columns[1]
            
            # ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³
            cdf['dna'] = cdf[cp].apply(get_detailed_dna)
            cdf[cpr] = pd.to_numeric(cdf[cpr].astype(str).str.replace(r'[^\d.]','',regex=True), errors='coerce').fillna(0)

            for i, row_our in self.our_df.iterrows():
                best_s = 0
                best_match = None
                
                # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ (Ø¨Ø¯ÙˆÙ† Vectorization Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø¥Ø¶Ø§Ø¹Ø© Ø£ÙŠ ÙØ±ØµØ©)
                # Ù‡Ø°Ø§ Ø£Ø¨Ø·Ø£ Ù‚Ù„ÙŠÙ„Ø§Ù‹ ÙˆÙ„ÙƒÙ†Ù‡ ÙŠØ¶Ù…Ù† ÙØ­Øµ ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª
                for j, row_comp in cdf.iterrows():
                    score, reason = self.calculate_match_quality(row_our['dna'], row_comp['dna'])
                    
                    if score > best_s:
                        best_s = score
                        best_match = row_comp

                if best_match is not None and best_s >= 65: # Ø¹ØªØ¨Ø© Ù‚Ø¨ÙˆÙ„ Ø°ÙƒÙŠØ©
                    p_our = float(row_our[self.our_pr])
                    p_comp = float(best_match[cpr])
                    diff = p_our - p_comp
                    
                    final_results.append({
                        "Ø§Ù„Ù…Ù†ØªØ¬": row_our[self.our_p],
                        "Ø§Ù„Ø³Ø¹Ø±": p_our,
                        "Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³": best_match[cp],
                        "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³": p_comp,
                        "Ø§Ù„ÙØ±Ù‚": diff,
                        "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚": best_s,
                        "Ø§Ù„Ù‚Ø±Ø§Ø±": "ðŸ”´ Ø³Ø¹Ø± Ø£Ø¹Ù„Ù‰" if diff > 5 else "ðŸŸ¢ Ø³Ø¹Ø± Ø£Ù‚Ù„" if diff < -5 else "âœ… Ù…ÙˆØ§ÙÙ‚",
                        "Ø§Ù„Ù…Ù†Ø§ÙØ³": comp_name
                    })
                
                if progress_callback and i % 20 == 0:
                    progress_callback(i / len(self.our_df))

        return pd.DataFrame(final_results)

def run_full_analysis(our_df, comp_dfs, progress_callback=None, mapping=None):
    engine = DeepIntegrityEngine(our_df, comp_dfs, mapping)
    return engine.run(progress_callback)

def find_missing_products(our_df, comp_dfs): return pd.DataFrame()
