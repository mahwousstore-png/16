"""
engine.py - ุงููุญุฑู ุงููุชุฌูู ุงูุณุฑูุน v17.2 (Vectorized Engine)
- ูุนุชูุฏ ุนูู TF-IDF & Cosine Similarity ูุณุฑุนุฉ ุชุตู ุฅูู 50x
- ููุชุฑุฉ ุตุงุฑูุฉ ูููุงุฑูุฉ ูุงูุญุฌู ูุชูููู ุงูุฃุฎุทุงุก
- ูุชูุงูู ุชูุงูุงู ูุน app.py v17.2
"""
import re
import pandas as pd
import numpy as np
import io
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ุงุณุชูุฑุงุฏ ุงูุฅุนุฏุงุฏุงุช (ุชุฃูุฏ ูู ุชุทุงุจู ุงูุฃุณูุงุก ูุน config.py)
try:
    from config import (
        REJECT_KEYWORDS, KNOWN_BRANDS, WORD_REPLACEMENTS,
        MATCH_THRESHOLD, HIGH_CONFIDENCE, REVIEW_THRESHOLD,
        PRICE_TOLERANCE, TESTER_KEYWORDS, SET_KEYWORDS
    )
except ImportError:
    # ููู ุงูุชุฑุงุถูุฉ ููุทูุงุฑุฆ
    MATCH_THRESHOLD = 60
    HIGH_CONFIDENCE = 90
    PRICE_TOLERANCE = 5
    REJECT_KEYWORDS = ["sample", "ุนููุฉ"]
    KNOWN_BRANDS = []
    WORD_REPLACEMENTS = {}

# ===== 1. ุฏูุงู ุงููุฑุงุกุฉ ูุงููุนุงูุฌุฉ (Helpers) =====

def read_file(uploaded_file):
    """ูุฑุงุกุฉ ููู CSV ุฃู Excel ุจูุฑููุฉ ุนุงููุฉ"""
    try:
        name = uploaded_file.name.lower()
        if name.endswith('.csv'):
            try:
                df = pd.read_csv(uploaded_file, encoding='utf-8')
            except:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        elif name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        else:
            return None, "ุตูุบุฉ ุงูููู ุบูุฑ ูุฏุนููุฉ"
        
        # ุชูุธูู ุฃุณูุงุก ุงูุฃุนูุฏุฉ (ุฅุฒุงูุฉ ุงููุณุงูุงุช ุงูุฒุงุฆุฏุฉ)
        df.columns = df.columns.str.strip()
        df = df.dropna(how='all')
        return df, None
    except Exception as e:
        return None, f"ุฎุทุฃ ุงููุฑุงุกุฉ: {str(e)}"

def normalize(text):
    """ุชูุญูุฏ ุงููุตูุต (ุนุฑุจู/ุฅูุฌููุฒู) ูููุทุงุจูุฉ"""
    if not isinstance(text, str): return ""
    t = text.strip().lower()
    # ุงุณุชุจุฏุงู ุงููููุงุช ุงูุดุงุฆุนุฉ (ูุซู EDP -> eau de parfum)
    for ar, en in WORD_REPLACEMENTS.items():
        t = t.replace(ar.lower(), en)
    # ุชูุธูู ุงูุฑููุฒ ูุชูุญูุฏ ุงูุนุฑุจูุฉ
    t = re.sub("[ุฅุฃุขุง]", "ุง", t)
    t = re.sub("ุฉ", "ู", t)
    t = re.sub("ู", "ู", t)
    t = re.sub(r'[^\w\s.]', ' ', t)
    t = re.sub(r'\s+', ' ', t).strip()
    return t

def extract_size(text):
    """ุงุณุชุฎุฑุงุฌ ุงูุญุฌู (ml)"""
    if not isinstance(text, str): return 0
    m = re.findall(r'(\d+(?:\.\d+)?)\s*(?:ml|ูู|ููู|g|ุบ)', text.lower())
    return float(m[0]) if m else 0

def extract_brand(text):
    """ุงุณุชุฎุฑุงุฌ ุงููุงุฑูุฉ ุจูุงุกู ุนูู ุงููุงุฆูุฉ ุงููุนุฑููุฉ"""
    if not isinstance(text, str): return ""
    tl = text.lower()
    for b in KNOWN_BRANDS:
        if b.lower() in tl:
            return b
    # ุฅุฐุง ูู ุชูุฌุฏ ูู ุงููุงุฆูุฉุ ุฎุฐ ุงููููุฉ ุงูุฃููู ูุงุฌุชูุงุฏ
    return text.split()[0] if text else ""

def extract_type(text):
    """ุงุณุชุฎุฑุงุฌ ููุน ุงูุนุทุฑ"""
    if not isinstance(text, str): return ""
    tl = text.lower()
    if any(k in tl for k in ['edp', 'eau de parfum', 'ุจุงุฑูููู', 'parfum']): return 'EDP'
    if any(k in tl for k in ['edt', 'eau de toilette', 'ุชูุงููุช']): return 'EDT'
    if any(k in tl for k in ['cologne', 'ููููู', 'edc']): return 'EDC'
    if any(k in tl for k in ['oil', 'ุฒูุช']): return 'Oil'
    return ''

def is_sample(text):
    if not isinstance(text, str): return False
    tl = text.lower()
    return any(k in tl for k in REJECT_KEYWORDS)

# ===== 2. ุงููุญุฑู ุงููุชุฌูู (The Vectorized Engine) =====

def run_full_analysis(our_df, comp_dfs, progress_callback=None):
    """
    ุชุญููู ูุงูู ุจุงุณุชุฎุฏุงู ุงููุตูููุงุช (Vectorization).
    ุงูุฃุณุฑุน ูุงูุฃุฏู ููุจูุงูุงุช ุงูุถุฎูุฉ.
    """
    results = []
    
    # ุชุญุฏูุฏ ุฃุนูุฏุชูุง
    our_col = next((c for c in ["ุงูููุชุฌ", "ุงุณู ุงูููุชุฌ", "Product", "Name", "name"] if c in our_df.columns), our_df.columns[0])
    our_price_col = next((c for c in ["ุงูุณุนุฑ", "ุณุนุฑ", "Price", "price", "Cost"] if c in our_df.columns), None)

    # ุชุฌููุฒ ุจูุงูุงุชูุง (ูุฑุฉ ูุงุญุฏุฉ)
    our_data = our_df.copy()
    # ุชูุธูู ูุงุณุชุฎุฑุงุฌ ุงูุฎุตุงุฆุต
    our_data['normalized'] = our_data[our_col].apply(normalize)
    our_data['brand'] = our_data[our_col].apply(extract_brand)
    our_data['size'] = our_data[our_col].apply(extract_size)
    
    # ุงุณุชุจุนุงุฏ ุงูุนููุงุช ูู ุงูููุงุฑูุฉ
    our_data = our_data[~our_data[our_col].apply(is_sample)]

    # ุฅุนุฏุงุฏ ุงููุญุฑู (TF-IDF)
    # ูุณุชุฎุฏู char_wb (ุญุฑูู ูุน ุญุฏูุฏ ูููุงุช) ููุฑููุฉ ุฃูุจุฑ ูู ุงูุฃููุงุฏ ูุงูุฃุณูุงุก
    vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=1)
    
    # ุชุฏุฑูุจ ุงููููุฐุฌ ุนูู ุจูุงูุงุชูุง
    try:
        our_vectors = vectorizer.fit_transform(our_data['normalized'].fillna(""))
    except ValueError:
        return pd.DataFrame() # ุจูุงูุงุช ูุงุฑุบุฉ

    total_steps = len(comp_dfs)
    
    for idx, (comp_name, comp_df) in enumerate(comp_dfs.items()):
        # ุชุญุฏูุซ ุดุฑูุท ุงูุชูุฏู ูู app.py
        if progress_callback: progress_callback((idx) / total_steps)
        
        # ุชุญุฏูุฏ ุฃุนูุฏุฉ ุงูููุงูุณ
        comp_prod_col = next((c for c in ["ุงูููุชุฌ", "ุงุณู ุงูููุชุฌ", "Product", "Name", "name"] if c in comp_df.columns), comp_df.columns[0])
        comp_price_col = next((c for c in ["ุงูุณุนุฑ", "ุณุนุฑ", "Price", "price"] if c in comp_df.columns), None)

        # ุชุฌููุฒ ุจูุงูุงุช ุงูููุงูุณ
        comp_data = comp_df.copy()
        comp_data = comp_data[~comp_data[comp_prod_col].apply(is_sample)] # ุงุณุชุจุนุงุฏ ุนููุงุช ุงูููุงูุณ
        comp_data['normalized'] = comp_data[comp_prod_col].apply(normalize)
        comp_data['brand'] = comp_data[comp_prod_col].apply(extract_brand)
        comp_data['size'] = comp_data[comp_prod_col].apply(extract_size)

        if comp_data.empty: continue

        # ุชุญููู ุจูุงูุงุช ุงูููุงูุณ ููุตูููุฉ
        try:
            comp_vectors = vectorizer.transform(comp_data['normalized'].fillna(""))
        except: continue

        # === ุงููุถุฑุจ ุงูุณุญุฑู: ุญุณุงุจ ุงูุชุดุงุจู (ุงููู ููุงุจู ุงููู) ===
        # ุงููุชูุฌุฉ ูุตูููุฉ ุถุฎูุฉ: [ุนุฏุฏ ููุชุฌุงุชูุง] ร [ุนุฏุฏ ููุชุฌุงุช ุงูููุงูุณ]
        similarity_matrix = cosine_similarity(our_vectors, comp_vectors)

        # ุงุณุชุฎุฑุงุฌ ุงููุชุงุฆุฌ
        for i, (our_idx, our_row) in enumerate(our_data.iterrows()):
            
            # ุตู ุงูุชุดุงุจูุงุช ููุฐุง ุงูููุชุฌ
            sim_scores = similarity_matrix[i]
            
            # --- ููุชุฑุฉ ุฐููุฉ (Post-Processing Filters) ---
            
            # 1. ููุชุฑ ุงููุงุฑูุฉ (Brand Lock)
            # ุฅุฐุง ุงุฎุชููุช ุงููุงุฑูุฉุ ุงุฌุนู ุงูุณููุฑ ุตูุฑ ููุฑุงู
            if our_row['brand']:
                brand_mask = comp_data['brand'].str.lower() != our_row['brand'].lower()
                sim_scores[brand_mask.values] = 0

            # 2. ููุชุฑ ุงูุญุฌู (Size Lock)
            # ูุณูุญ ุจุงุฎุชูุงู ุจุณูุท (ูุซูุงู 5 ูู)
            if our_row['size'] > 0:
                size_diff = np.abs(comp_data['size'].values - our_row['size'])
                size_mask = size_diff > 5 # ุงุฎุชูุงู ุฃูุซุฑ ูู 5 ูู
                sim_scores[size_mask] *= 0.5 # ุนูุงุจ ููู ููุงุฎุชูุงู

            # ุงูุนุซูุฑ ุนูู ุฃูุถู ุชุทุงุจู ุจุนุฏ ุงูููุชุฑุฉ
            best_match_idx = sim_scores.argmax()
            best_score = sim_scores[best_match_idx] * 100

            if best_score >= MATCH_THRESHOLD:
                comp_row = comp_data.iloc[best_match_idx]
                
                # ุงุณุชุฎุฑุงุฌ ุงูุฃุณุนุงุฑ
                our_p = float(our_row[our_price_col]) if our_price_col else 0
                comp_p = float(comp_row[comp_price_col]) if comp_price_col else 0
                
                # ุชุฌุงูู ุงูุฃุณุนุงุฑ ุงูุตูุฑูุฉ
                if our_p <= 1 or comp_p <= 1: continue

                diff = our_p - comp_p
                
                # ููุทู ุงููุฑุงุฑ
                decision = "โ ููุงูู"
                risk = "ููุฎูุถ"
                
                if diff > PRICE_TOLERANCE:
                    decision = "๐ด ุณุนุฑ ุฃุนูู"
                    risk = "ุนุงูู"
                elif diff < -PRICE_TOLERANCE:
                    decision = "๐ข ุณุนุฑ ุฃูู"
                
                if best_score < HIGH_CONFIDENCE:
                    decision = "โ๏ธ ูุฑุงุฌุนุฉ"
                    risk = "ูุชูุณุท"

                results.append({
                    "ุงูููุชุฌ": our_row[our_col],
                    "ุงูุณุนุฑ": our_p,
                    "ุงููุงุฑูุฉ": our_row['brand'],
                    "ุงูุญุฌู": f"{int(our_row['size'])}ml" if our_row['size'] else "",
                    "ุงูููุน": extract_type(our_row[our_col]),
                    "ููุชุฌ ุงูููุงูุณ": comp_row[comp_prod_col],
                    "ุณุนุฑ ุงูููุงูุณ": comp_p,
                    "ุงููุฑู": round(diff, 2),
                    "ูุณุจุฉ ุงูุชุทุงุจู": round(best_score, 1),
                    "ุงููุฑุงุฑ": decision,
                    "ุงูุฎุทูุฑุฉ": risk,
                    "ุงูููุงูุณ": comp_name,
                    # ุญููู ููุชูุงูู ูุน ุงูุชุตุฏูุฑ
                    "ุฌููุน ุงูููุงูุณูู": [] 
                })

    if progress_callback: progress_callback(1.0)
    return pd.DataFrame(results)


def find_missing_products(our_df, comp_dfs):
    """
    ูุณุฎุฉ ุณุฑูุนุฉ ุฌุฏุงู ูุฅูุฌุงุฏ ุงูููููุฏุงุช ุจุงุณุชุฎุฏุงู ุงูู Sets (Hashing)
    ุจุฏูุงู ูู ุชูุฑุงุฑ ุงูุญููุงุช ุงูุจุทูุฆุฉ
    """
    missing = []
    
    # 1. ุชุฌููุฒ ูุงุฆูุฉ ููุชุฌุงุชูุง ูู "ุจุตูุงุช" (Hash Set)
    our_col = next((c for c in ["ุงูููุชุฌ", "ุงุณู ุงูููุชุฌ", "Product", "Name", "name"] if c in our_df.columns), our_df.columns[0])
    # ูุณุชุฎุฏู ุงูุชุทุจูุน ุงูุฏููู ูุฅูุดุงุก ุงูุจุตูุฉ
    our_fingerprints = set(our_df[our_col].astype(str).apply(normalize).tolist())
    
    for comp_name, comp_df in comp_dfs.items():
        comp_prod_col = next((c for c in ["ุงูููุชุฌ", "ุงุณู ุงูููุชุฌ", "Product", "Name", "name"] if c in comp_df.columns), comp_df.columns[0])
        comp_price_col = next((c for c in ["ุงูุณุนุฑ", "ุณุนุฑ", "Price", "price"] if c in comp_df.columns), None)
        
        for _, row in comp_df.iterrows():
            p_name = str(row[comp_prod_col])
            if is_sample(p_name): continue
            
            p_fingerprint = normalize(p_name)
            
            # ุจุญุซ ููุฑู (O(1) complexity)
            if p_fingerprint not in our_fingerprints:
                # ุชุญูู ุฅุถุงูู: ูู ุงูุงุณู ูุตูุฑ ุฌุฏุงู ููููู ูููุฏุงูุ
                if len(p_fingerprint) < 4: continue
                
                price = 0
                if comp_price_col:
                    try: price = float(row[comp_price_col])
                    except: pass
                
                missing.append({
                    "ููุชุฌ ุงูููุงูุณ": p_name,
                    "ุณุนุฑ ุงูููุงูุณ": price,
                    "ุงูููุงูุณ": comp_name,
                    "ุงููุงุฑูุฉ": extract_brand(p_name),
                    "ุงูููุน": extract_type(p_name),
                    "ุงูุญุฌู": extract_size(p_name)
                })

    return pd.DataFrame(missing)


# ===== ุฏูุงู ุงูุชุตุฏูุฑ (ูุทููุจุฉ ูู app.py) =====
def export_excel(df, sheet_name="ุงููุชุงุฆุฌ"):
    output = io.BytesIO()
    export_df = df.copy()
    if "ุฌููุน ุงูููุงูุณูู" in export_df.columns:
        export_df = export_df.drop(columns=["ุฌููุน ุงูููุงูุณูู"])
    # ุชุตุญูุญ ุชุฑุชูุจ ุงูุฃุนูุฏุฉ ููุฃูุงูุฉ
    cols_order = ["ุงูููุชุฌ", "ุงูุณุนุฑ", "ููุชุฌ ุงูููุงูุณ", "ุณุนุฑ ุงูููุงูุณ", "ุงููุฑู", "ูุณุจุฉ ุงูุชุทุงุจู", "ุงููุฑุงุฑ", "ุงูููุงูุณ", "ุงููุงุฑูุฉ"]
    available_cols = [c for c in cols_order if c in export_df.columns]
    remaining_cols = [c for c in export_df.columns if c not in cols_order]
    export_df = export_df[available_cols + remaining_cols]
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        export_df.to_excel(writer, sheet_name=sheet_name[:31], index=False)
    return output.getvalue()

def export_section_excel(df, section_name):
    return export_excel(df, sheet_name=section_name[:31])
