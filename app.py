"""
Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¹ÙŠØ± Ø§Ù„Ø°ÙƒÙŠ - Ù…Ù‡ÙˆÙˆØ³ v17.6 (Manual Column Mapping)
- Ù…ÙŠØ²Ø© Ø¬Ø¯ÙŠØ¯Ø©: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¯Ù‚Ø© 100%.
"""
import streamlit as st
import pandas as pd
import time
from config import *
from styles import get_styles, stat_card, vs_card
from engines.engine import (read_file, run_full_analysis, find_missing_products, 
                            export_excel, export_section_excel)
from engines.ai_engine import (chat_with_ai, verify_single_match, analyze_product, 
                               smart_bulk_verify, suggest_price, call_ai_json)
from utils.helpers import (TaskManager, apply_filters, get_filter_options, export_to_excel, 
                           export_multiple_sheets, parse_pasted_text, format_price, format_diff)
from utils.make_helper import (send_price_updates, send_new_products, send_missing_products, 
                               verify_webhook_connection, export_to_make_format)
from utils.db_manager import (init_db, log_event, log_decision, log_analysis, 
                              get_events, get_decisions, get_analysis_history)

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title=APP_TITLE, page_icon=APP_ICON, layout="wide", initial_sidebar_state="expanded")
st.markdown(get_styles(), unsafe_allow_html=True)
init_db()

# ===== Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„Ø© =====
if 'results' not in st.session_state: st.session_state.results = None
if 'task_id' not in st.session_state: st.session_state.task_id = None
if 'chat_history' not in st.session_state: st.session_state.chat_history = []
if 'our_df_preview' not in st.session_state: st.session_state.our_df_preview = None
if 'comp_df_preview' not in st.session_state: st.session_state.comp_df_preview = None

# ===== Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ =====
with st.sidebar:
    st.markdown(f"## {APP_ICON} {APP_TITLE}")
    st.caption(f"Engine: v17.6 (Manual Mapping)")
    page = st.radio("Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", SECTIONS, label_visibility="collapsed")
    st.markdown("---")
    if st.session_state.results:
        r = st.session_state.results
        st.markdown("**ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©:**")
        st.caption(f"ğŸ”´ Ø±ÙØ¹ Ø³Ø¹Ø±: {len(r.get('price_raise', []))}")
        st.caption(f"ğŸŸ¢ Ø®ÙØ¶ Ø³Ø¹Ø±: {len(r.get('price_lower', []))}")
        st.caption(f"ğŸ” Ù…ÙÙ‚ÙˆØ¯Ø§Øª: {len(r.get('missing', []))}")

# ===== Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ© =====
if st.session_state.task_id:
    status = TaskManager.get_status(st.session_state.task_id)
    if status['status'] == 'running':
        st.info(f"â³ {status['message']} ({status['progress']}%)")
        my_bar = st.progress(status['progress'])
        time.sleep(1)
        st.rerun()
    elif status['status'] == 'completed':
        st.success("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
        st.balloons()
        full_df = status['result']
        results = {
            "price_raise": full_df[full_df["Ø§Ù„Ù‚Ø±Ø§Ø±"].str.contains("Ø£Ø¹Ù„Ù‰", na=False)],
            "price_lower": full_df[full_df["Ø§Ù„Ù‚Ø±Ø§Ø±"].str.contains("Ø£Ù‚Ù„", na=False)],
            "approved": full_df[full_df["Ø§Ù„Ù‚Ø±Ø§Ø±"].str.contains("Ù…ÙˆØ§ÙÙ‚", na=False)],
            "review": full_df[full_df["Ø§Ù„Ù‚Ø±Ø§Ø±"].str.contains("Ù…Ø±Ø§Ø¬Ø¹Ø©", na=False)],
            "all": full_df,
            "missing": find_missing_products(st.session_state.our_df_cache, st.session_state.comp_dfs_cache)
        }
        st.session_state.results = results
        st.session_state.task_id = None
        TaskManager.clear_task(st.session_state.task_id)
        st.rerun()
    elif status['status'] == 'failed':
        st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {status['message']}")
        st.session_state.task_id = None

# ===== ØµÙØ­Ø© Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª (Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©) =====
if page == "ğŸ“‚ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª":
    st.header("ğŸ“‚ Ù…Ø±ÙƒØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©")
    
    col1, col2 = st.columns(2)
    with col1:
        our_file = st.file_uploader("ğŸ“¦ Ù…Ù„Ù Ù…Ù†ØªØ¬Ø§ØªÙ†Ø§", type=["csv", "xlsx"])
    with col2:
        comp_files = st.file_uploader("ğŸª Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†", type=["csv", "xlsx"], accept_multiple_files=True)

    # Ù‚Ø±Ø§Ø¡Ø© Ø£ÙˆÙ„ÙŠØ© Ù„Ù„Ù…Ù„ÙØ§Øª Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    if our_file:
        try:
            if st.session_state.our_df_preview is None:
                df, _ = read_file(our_file)
                st.session_state.our_df_preview = df
        except: pass

    if comp_files and len(comp_files) > 0:
        try:
            if st.session_state.comp_df_preview is None:
                df, _ = read_file(comp_files[0]) # Ù‚Ø±Ø§Ø¡Ø© Ø£ÙˆÙ„ Ù…Ù„Ù Ù…Ù†Ø§ÙØ³ ÙƒØ¹ÙŠÙ†Ø©
                st.session_state.comp_df_preview = df
        except: pass

    # Ù…Ù†Ø·Ù‚Ø© ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Mapping)
    mapping = {}
    if st.session_state.our_df_preview is not None and st.session_state.comp_df_preview is not None:
        st.info("ğŸ‘‡ ÙŠØ±Ø¬Ù‰ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù„Ø¶Ù…Ø§Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„")
        
        with st.expander("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹)", expanded=True):
            c1, c2 = st.columns(2)
            
            # Ø£Ø¹Ù…Ø¯Ø© Ù…Ù„ÙÙ†Ø§
            with c1:
                st.markdown("**Ø¨ÙŠØ§Ù†Ø§ØªÙ†Ø§:**")
                our_cols = st.session_state.our_df_preview.columns.tolist()
                mapping['our_name'] = st.selectbox("Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬ (Ø¹Ù†Ø¯Ù†Ø§)", our_cols, index=0)
                mapping['our_price'] = st.selectbox("Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø³Ø¹Ø± (Ø¹Ù†Ø¯Ù†Ø§)", our_cols, index=min(1, len(our_cols)-1))
            
            # Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ø§ÙØ³
            with c2:
                st.markdown("**Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ (Ø¹ÙŠÙ†Ø©):**")
                comp_cols = st.session_state.comp_df_preview.columns.tolist()
                mapping['comp_name'] = st.selectbox("Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬ (Ø§Ù„Ù…Ù†Ø§ÙØ³)", comp_cols, index=0)
                mapping['comp_price'] = st.selectbox("Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø³Ø¹Ø± (Ø§Ù„Ù…Ù†Ø§ÙØ³)", comp_cols, index=min(1, len(comp_cols)-1))

        if st.button("ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ", type="primary", disabled=st.session_state.task_id is not None):
            # Ø¥Ø¹Ø§Ø¯Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ù„ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ù„Ù„Ù…Ø­Ø±Ùƒ
            our_df, _ = read_file(our_file)
            comp_dfs = {}
            for f in comp_files:
                cdf, _ = read_file(f)
                if cdf is not None: comp_dfs[f.name] = cdf
            
            st.session_state.our_df_cache = our_df
            st.session_state.comp_dfs_cache = comp_dfs
            
            # ØªÙ…Ø±ÙŠØ± Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„Ù…Ø­Ø±Ùƒ
            task_id = TaskManager.start_task(run_full_analysis, our_df, comp_dfs, mapping=mapping)
            st.session_state.task_id = task_id
            st.rerun()
            
    elif our_file or comp_files:
        st.warning("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ø¸Ù‡ÙˆØ± Ø®ÙŠØ§Ø±Ø§Øª ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©.")

# ===== Ø¨Ù‚ÙŠØ© Ø§Ù„ØµÙØ­Ø§Øª ÙƒÙ…Ø§ Ù‡ÙŠ =====
elif page in ["ğŸ”´ Ø³Ø¹Ø± Ø£Ø¹Ù„Ù‰", "ğŸŸ¢ Ø³Ø¹Ø± Ø£Ù‚Ù„", "âœ… Ù…ÙˆØ§ÙÙ‚ Ø¹Ù„ÙŠÙ‡Ø§", "âš ï¸ ØªØ­Øª Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©"]:
    key_map = {"ğŸ”´ Ø³Ø¹Ø± Ø£Ø¹Ù„Ù‰": "price_raise", "ğŸŸ¢ Ø³Ø¹Ø± Ø£Ù‚Ù„": "price_lower", 
               "âœ… Ù…ÙˆØ§ÙÙ‚ Ø¹Ù„ÙŠÙ‡Ø§": "approved", "âš ï¸ ØªØ­Øª Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©": "review"}
    current_key = key_map[page]
    
    if st.session_state.results and current_key in st.session_state.results:
        df = st.session_state.results[current_key]
        st.header(f"{page} ({len(df)})")
        
        with st.expander("ğŸ” ÙÙ„Ø§ØªØ±"):
            f_opts = get_filter_options(df)
            c1, c2 = st.columns(2)
            filters = {
                "search": c1.text_input("Ø¨Ø­Ø«", key=f"s_{current_key}"),
                "brand": c2.selectbox("Ø§Ù„Ù…Ø§Ø±ÙƒØ©", f_opts["brands"], key=f"b_{current_key}")
            }
        
        filtered_df = apply_filters(df, filters)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        for i, row in filtered_df.iterrows():
            st.markdown(vs_card(
                row.get("Ø§Ù„Ù…Ù†ØªØ¬"), row.get("Ø§Ù„Ø³Ø¹Ø±"), 
                row.get("Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§ÙØ³"), row.get("Ø³Ø¹Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³"), 
                row.get("Ø§Ù„ÙØ±Ù‚"), row.get("Ø§Ù„Ù…Ù†Ø§ÙØ³")
            ), unsafe_allow_html=True)
            st.markdown("---")
    else:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª.")

elif page == "ğŸ” Ù…Ù†ØªØ¬Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø©":
    if st.session_state.results and "missing" in st.session_state.results:
        st.dataframe(st.session_state.results["missing"], use_container_width=True)
    else:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙÙ‚ÙˆØ¯Ø§Øª.")

elif page == "ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…":
    st.title("Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")

elif page == "ğŸ¤– Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ":
    st.header("Ù…Ø³Ø§Ø¹Ø¯ AI")
    q = st.text_input("Ø³Ø¤Ø§Ù„Ùƒ:")
    if q: st.write(chat_with_ai(q)['response'])
